{"./":{"url":"./","title":"关于本书","keywords":"","body":"本书的阅读指南 动书 是为了方便使用人工智能、增强现实、虚拟现实、物联网等数字教科书而开发的。这本互动书是ActionBook系列的第一本出版物 https://yuanzhuo.bnu.edu.cn/actionbook 本书以简单有趣的方式向9至15岁的孩子介绍人工智能。它还介绍了一些基于人工智能的解决方案的生动故事，这些解决方案是为了对抗流行病而开发的。此外，本书还通过展示简单的编程代码，让孩子们可以在JupyterLab环境上使用和实现，从而提供了关于人工智能的实践学习体验。 在读本内容上（章、节和故事）使用了三个年龄标签。每个标签表示该内容的年龄适宜性，说明如下: 标签标注了适合9岁以上读者阅读的章节。 标签标注了适合11岁及以上读者阅读的章节。 标签标注了适合13岁及以上读者阅读的章节。 读本各章、节和故事的年龄适宜性是根据Coh-Metrix软件和几位人工智能老师的意见确定的。Coh-Metrix是一种计算工具，可以产生文本语言和话语表征的指数（Graesser等，2004；McNamara等，2014）。所产生的输出值可以用许多不同的方式来研究交互式图书文本的难度、可读性和心理表征的一致性等。 文中的每个 \"粗体字\"术语都有一个文本框定义，旨在为读者进一步解释该术语。此外，在每一节的最后，都以小测验或思考题的形式给出了一个练习，以帮助读者练习该节所获得的知识。 该读本也可以供其他不同年龄段的人阅读，即使他们可能没有任何关于人工智能相关知识。家长和老师也可以利用这个读本向青少年介绍人工智能，引导他们与代码互动。 在这本互动书中使用JupyterHub [!NOTE] 推荐使用浏览器: Google Chrome, Microsoft Edge 和 Firefox. 本书基于人工智能的交互式版本，读者可以与所介绍的内容和代码进行交互 (测试、修改和下载)借由平台： Yuanzhuo Online Code Platform. 在这本书中，你可以找到互动部分的章节: 2.3, 3.3, 3.4, 4.3 and 5.3. 你可以使用给定的 用户名 yuanzhuo and 密码 yuanzhuo, 或者通过以下的指导 创建你自己的服务器. 什么是JupyterHub JupyterHub是为多个用户提供Jupyter Notebook服务的最佳方式。它可以用于学生班级、企业数据科学小组或科研小组。它是一个多用户Hub，可以生成、管理和代理多个单用户Jupyter笔记本服务器的实例。 Jupyter Notebook是一个开源的Web应用程序，允许您创建和共享包含实时代码、方程、可视化和叙述性文本的文档。用途包括：数据清理和转换、数值模拟、统计建模、数据可视化、机器学习等。 如何注册并登录平台 1.点击 Yuanzhuo Online Code Platform 2.点击‘联系管理员’或直接访问发送私信申请开通账号 3.通过你的用户名和密码进行登录 4.点击 My Server,您可以从本页面下载源码上传到您的服务器. 如果您想安装其他软件包，请点击新建-终端，我们支持用户通过以下方式安装新的软件包 pip3 install --user 强烈建议使用Anaconda虚拟环境。 echo 'export PATH=/opt/anaconda/bin:$PATH' >> ~/.bashrc && source ~/.bashrc conda create -n myspace conda activate myspace # 如需使用公共内核，需要安装ipykernel. conda install ipykernel 权利和许可 此出版物在遵循共享3.0 IGO (CC-BY-SA 3.0 IGO）许可证 (http://creativecommons.org/licenses/by-sa/3.0/igo/)下提供开放访问 请按以下方式引用该作品 黄荣怀，刘德建，胡祥恩，Tlili, A，翁仲铭，樊磊，罗明勇，姚茜，Shubeck, K，张香玲，陈虹宇（2020）.人工智能助力新冠疫情防控网络互动读本.北京：北京师范大学智慧学习研究院. 联系我们 如果您有任何问题，请发送电子邮件到 yuanzhuo@bnu.edu.cn. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/Preface.html":{"url":"content/Preface.html","title":"Preface","keywords":"","body":"Preface Artificial Intelligence (AI) has been one of the emerging technologies that has been frequently used in our daily life in different domains, including, education, medicine, finance, etc. However, even though AI is frequently used and mentioned in the media, there is still lack of AI understanding. Technological literacy is also very important now, because children are growing up in smart environments where they interact with intelligent devices, like robots and tablets. As children gain exposure and understanding of AI technology, their reasoning about these devices becomes more thoughtful and nuanced. Currently, educators lack information on how to teach teenagers AI, but there is a tremendous need for this to happen rapidly given this pandemic. Several AI solutions (e.g., using robotics, face recognition, etc.) have been developed to combat several crises, including the current COVID-19 pandemic. It is therefore important to prepare the young generation for the next crisis/pandemic in the era of AI. The more knowledgeable the upcoming generation is of AI technologies, the more likely they are to develop smart solutions that will serve for the well-being of humans in crisis and maintain several vital activities, including economical, educational and health activities. Based on the above background, this book introduces AI to children, between the age of 9 and 15, in an easy and fun way. It also presents vivid stories about some AI-based solutions that were developed to combat the pandemic. Furthermore, this book presents hands-on learning experience about AI by showing simple programming code that children could use and implement on the JupyterLab environment. JupyterLab is an open-source web-based interactive development environment that can support a wide range of workflows in data science, scientific computing, and machine learning. The book is structured according to the Five Big Ideas in AI developed by Computer Science Teachers Association (CSTA) for K-12 students, namely perception, representation and reasoning, learning, natural interaction and societal impact. The interactive AI-based version of this book, where readers can interact with the presented content and code (test, modify and download it), can be found on the Jupyter environment: http://yuanzhuo.bnu.edu.cn/article/653 It should be noted that this book can also be read by other people with different ages who may not have any background about AI. Parents and teachers can also use this book to introduce AI to their children or students respectively, and guide them to interact with the presented code online. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/Acknowledgement.html":{"url":"content/Acknowledgement.html","title":"Acknowledgement","keywords":"","body":"Acknowledgement Many people have helped us in finalizing this book. They have our great appreciation for the long hours and hard work they devoted to conducting research and developing the content. Without their incredible assistance, this book would not have been possible. We would like to acknowledge the help of several researchers who worked on developing the contents and organizing the webinar for this book, namely Lei Fan, Zhong Ren, Ting-Wen Chang, Rongxia Zhuang, Wei Zhou, Junxiu Wang, Bojun Gao, Yihong Shi, Zhonglin Zhao, Jiajia Liu. We would like also to acknowledge the contribution of multiple international partners, researchers, and staff who provided new ideas for this handbook during the organized webinar. Thanks also go to those experts from the Smart Learning Institute of Beijing Normal University (SLIBNU), UNESCO International Research and Training Center for Rural Education (UNESCO INRULED), International Association of Smart Learning Environments (IASLE), Arab League's Educational, Cultural and Scientific Organization (ALECSO)， The University of Memphis and Edmodo for their professional feedback and comments during the preparation of this book. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/Chapter 1 What is Artificial Intelligence.html":{"url":"content/Chapter 1 What is Artificial Intelligence.html","title":"Chapter 1 What is Artificial Intelligence?","keywords":"","body":"Chapter 1 What is Artificial Intelligence? Artificial intelligence (AI) is not only about robots as shown in movies, for instance “I, Robot” movie (see Figure 2). It is much bigger than that; It has been a research area in computer science and engineering. Now, it is part of our life. There are many different types of AI. AI is about making machines, such as computers, be smart and mimic human behaviors. Artificial (/ˌɑr təˈfɪʃ əl/) Something made or produced by people, often as a copy of something natural. Intelligence (/ɪnˈtɛl ɪ dʒəns/) The ability to learn, think, understand, and make decisions that are based on reasoning. Figure 1. AI representation in movies In fact, we are interacting and communicating with 'machines' all the time, they are like one of us. The field of AI that made this possible is called speech recognition. AI-enabled computers (we also call them machines, or in some countries, we simply call them electronic brain) can now read and write text like humans, and the type of AI that allows this to happen is called Natural Language Processing (NLP). In addition to the ability of language processing, scientists have made computers do other things that are uniquely to human, we call 'higher order cognitive abilities' such as thinking, reasoning, and decision making. It has been shown that these abilities of human brain are largely due to its special interaction style between neurons (the basic elements of human brain). Scientists enable computers with these higher-order cognitive capability by implementing something called 'brain-style computation' between neural networks. To implement these presented examples, AI relies on analyzing data using several algorithms to achieve its objective. Figure 2 presents examples of how AI technologies could mimic human actions and behaviors. Network (/ˈnɛtˌwɜrk/) A large system consisting of many similar parts, such as lines, tubes, nerves, etc. that are connected to each other and operate together. Data (/ˈdeɪtə, ˈdætə, ˈdɑtə/) Information, especially facts or numbers, collected to be examined and used to discover things or to make decisions. Data could be in different formats, such as text, picture or audio. Algorithm (/ˈælgəˌrɪðəm/) A list of instructions or a set of rules to be followed for solving a problem. Figure 2. Examples of how AI technologies could mimic human actions AI, as a common term in our language, and AI-enabled devices are playing critical role in our everyday life. They are used almost everywhere, maybe without you knowing about it. For instance, did you know that AI is used in many games that you are playing, to control Non-Player Characters (NPCs) or bots, like in Fortnite or any other game? Did you know that AI is even is used in our smart phones to talk to Siri, for example? In fact, almost everything you see or do at any moment are enabled by AI to some degree. The book you are reading, yes, this book, has been a product of AI enabled computer programs. AI have been part of entire life-cycle of every product of modern civilization. Feel free to point to anything you may see at this time, we are sure that AI-enabled technologies, environments, etc. have been part of the production process. These are not limited to the games you play, or smart phones you use. When AI was first introduced; it was to make human's job more efficient. Now, more and more AI-enabled devices, AI-enabled processes and environments are making our lives easier and enjoyable. In this book, we give examples and facts about AI to humans: AI is actually \"saving\" human life, during crises and pandemics, like this COVID-19 pandemic. In this case, AI can be our super heroes that try to protect and keep us safe by being used in different ways. Therefore, to truly appreciate AI, we need to learn about it. It is also possible for you to be a super hero, like Sun Wukong (孙悟空) or Batman, and use AI to save lives in the future. However, as a first step, we need to understand AI together and learn how it can be a super hero. Therefore, this book attempts to explain in an easy and fun way, the basics of AI. It also presents vivid stories from different countries about how AI is being used to combat the COVID-19 pandemic. Let’s finish reading this book and get ready to be a super hero in the future! Coronavirus (/kəˈroʊnəˌvaɪrəs/) Coronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19. Story 1: The AI history Artificial Intelligence (AI) goes back to a time far, far away from this time, when there were no smart phones, no internet, and no fast cars. Philosophers started studying the human body and its structure, and described human thinking as a symbolic system. Ancient Greeks had myths about robots, while Egyptians built some automated systems (systems that work on their own), but back then, the term “Artificial Intelligence” did not exist. In 1952, Arthur Samuel, surprised the world, by making the first computer checkers-playing program and the first computer program to learn on its own. This computer was way bigger than computers we know nowadays (see Figure 3). After several years, specifically in 1956, the term “Artificial Intelligence” was finally coined at a conference at Dartmouth College in Hanover, New Hampshire-, United States. Three years later, the Massachusetts Institute of Technology (MIT) AI Lab was built. Later, with the help of newly invented technology, such as the Internet and smart chips, AI started to become more helpful and easier to use. Now, we can see AI with us wherever we go (like hospitals) and in things we use every day (like our smart phones). Symbolic (/sɪmˈbɒlɪk/) System (/ˈsɪstəm/) A system that computes and communicates using symbols. Program (/ˈproʊgræm, -grəm/) A set of coded instructions that make a computer perform an operation. Figure 3. First computer checkers-playing program Reflection exercise Data mining is an essential part of AI. You almost can guess its meaning by the word \"mining\". If you understand the process of Coal mining or Oil mining, try to come up your OWN definition of Data mining and compare it to the textbook definition of data mining. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/Chapter 2 Perception How computers recognize the world like humans do.html":{"url":"content/Chapter 2 Perception How computers recognize the world like humans do.html","title":"Chapter 2 Perception: How computers recognize the world like humans do?","keywords":"","body":"Chapter 2 Perception: How computers recognize the world like humans do? Perception is one of the most important abilities for human and some animals. It is the ability to help animals (humans included) be aware of physical environments. It has been primarily associated biological species. Different animals are equipped with different perception abilities. Human perception is the ability to see, hear, or become aware of your surroundings through the senses. As shown in Figure 4, while the human body perceives the world with its five senses (sight, sound, smell, taste and touch), computers mimic, or copy, human intelligence and use different sensors (cameras, sound detectors, etc.), similar to the human senses, to perceive the world. Making computers “see” and “hear” like humans is one of the important AI achievements. Figure 4. Examples of how humans and computers perceive the world Sensor (/ˈsɛnsɔr, -sər/) A sensor is a device that measures physical input from its environment and converts it into data that can be read by humans or machines. For instance, it is possible to find sensors that detect noises, heart beats, etc. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/2.1 Utilizing face recognition for tracking quarantine evaders during COVID-19.html":{"url":"content/2.1 Utilizing face recognition for tracking quarantine evaders during COVID-19.html","title":"2.1 Utilizing face recognition for tracking quarantine evaders during COVID-19","keywords":"","body":"2.1 Utilizing face recognition for tracking quarantine evaders during COVID-19 Recognizing faces is one of the first developed human instincts. Small babies need to recognize the faces of their parents from other faces so they can connect to them. In this context, babies start staring and seeing their parents’ faces (for instance, during breastfeeding) until they memorize them. They can then start seeing the difference between their parents’ faces and unfamiliar faces. Similarly, computers mimic human behavior and intelligence and, instead of using human eyes, they use sensors (cameras) to identify faces. Facial recognition is based on the geometric characteristics of the face (the shape of eyes, nose, mouth and the geometric relationship between them (the distance between them). Geometric (/ˌdʒiəˈmɛtrɪk/) Characteristics (/ˌkærɪktəˈrɪstɪks/) They are visual characteristics that made up of shapes such as squares, triangles, or rectangles. Facial recognition involves, as shown in Figure 5, the following four steps. Face Detection: Locate one or more faces in the image and mark with a bounding box. Face Alignment: Normalize the face to be consistent with the database, such as geometry and photometrics. Feature Extraction: Select features from the face that can be used for the recognition task. Face Recognition: Compare the face to one or more known faces in a prepared database. Figure 5. Face detection process Facial (/ˈfeɪʃəl/) Recognition (/ˌrɛk əgˈnɪʃən/) Facial recognition is a way of recognizing a human face through technology. A facial recognition system uses biometrics to map facial features from a photograph or video. It compares the information with a database of known faces to find a match. Story 2: Using robots for face mask detection during COVID-19 “Your temperature is normal. Please wear a mask”, say AIMBOT. AIMBOT is an intelligent patrol robot that reports and reminds people to wear a mask, as shown in Figure 6. When multiple people enter together, it can also conduct multiple face detections and mask identifications. Then it can remind everyone to keep practicing social distancing in order to reduce the risk of infection. How can AIMBOT do this? Even humans cannot measure their body temperature with only their eyes. It uses an infrared sensor in addition to its visible light binocular camera (like human eyes) to identify the visitor's mask on their faces and body temperature. Figure 6. A photo of AIMBOT being in use Infrared (/ˌɪnfrəˈrɛd/) It is a type of light that cannot be seen with the naked eye, but can be felt in the form of heat. Story 3: Using face recognition for tracking quarantine evaders during COVID-19 The COVID-19 virus is very tricky. After infecting people, it has an incubation period of about 14 days in the body. An “incubation period” means the amount of time it takes before a person starts showing symptoms, like a fever, or coughing. An incubation period of 14 days means a person can have the virus for two whole weeks before they realize it. You may be worried and asking yourself, \"How can I tell if I'm surrounded by infected people? Especially if they do not have any symptoms? How many people are in close contact with them? \" Bingo! People's mobile trajectory data can tell us! The trajectory data can tell you where the patient has been and whether you've been there. For example, the Beijing JianKang APP uses the camera to detect the person’s face. It then shows the current status of that person. As shown in Figure 7, the green word indicates that the health of that person is good, while the yellow word indicates that the person should be home quarantined. Many supermarkets, parks and other public places in China used this APP to allow only those who are healthy to enter these places to protect more people. Figure 7: Screenshot of JianKang application Incubation (/ˌɪnkyəˈbeɪʃən, ˌɪŋ-/) Period (/ˈpɪəriəd/) The period of time between harmful bacteria or viruses entering a person's or animal's body, or entering a plant, and the symptoms of a disease appearing. Mobile (/ˈmoʊbəl, -baɪl/) Trajectory (/trəˈdʒɛktəri/) Data (/ˈdeɪ tə, ˈdætə, ˈdɑtə/) Data that show the curved path of somebody or something moving from one place to another. The following challenges can make it difficult for computers to recognize a face. Pose variations: It is sometimes difficult for humans to recognize others, for instance, their friends when they are looking at them from different angles. Similarly, head movements, which can be described by the egocentric rotation angles, i.e. pitch, roll and yaw, or camera changing point of views could lead to major changes in facial appearance and/or shape and generate individual variations (differences), making automated facial recognition across pose a difficult task for computers. Variation (/ˌvɛəriˈeɪʃən/) A change in the amount or level of something. Facial expression changes: Even more differences could be caused by a person making different facial expressions. A person might change their face because they are in different emotional states (happy, angry, confused, etc.) like the ones in Figure 8. So, efficiently and automatically recognizing the different facial expressions is important for both the evaluation of emotional states and the automated face recognition. Figure 8. Face expressions based on different emotional states Aging of the face: Another reason of face appearance's changes could be caused by the aging of the human face, and could impact on the entire process if the time between each image capture is significant. Varying illumination conditions: It is sometimes difficult for humans to identify others when it is a bit dark (for instance at night). Similarly, large variations of light and dark could degrade the performance of recognizing a given face. Indeed, for low levels of lighting of the background or foreground, face detection and recognition are much harder to perform, since shadows could appear on the face and facial patterns could look the same, as shown in Figure 9. Figure 9. Shadow variation based on the lightning position © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/2.2 Utilizing speech recognition for automatic phone responses during COVID-19.html":{"url":"content/2.2 Utilizing speech recognition for automatic phone responses during COVID-19.html","title":"2.2 Utilizing speech recognition for automatic phone responses during COVID-19","keywords":"","body":"2.2 Utilizing speech recognition for automatic phone responses during COVID-19 Similar to the example shown above (see section 2.1), babies start listening at an early age to their parents’ voices and recognize them. They can hear the difference from their voices and strangers’ voices, so they might find more comfort from their parents’ voices than a stranger’s voice. However, unlike humans, computers do not have ears that let them hear sounds, or brains to understand that the sounds are words or phrases. Therefore, they use sensors, like voice detectors (just like the human ears), to detect speech. Specifically, there are three main stages involved in speech recognition: Preprocessing involves taking the speech sounds and turning it into something the computer can use. Specifically, when we speak, we create vibrations in the air. The computer then uses an analog-to-digital converter (ADC) to translate this analog wave into digital data that it can understand. To do this, it samples, or digitizes, the sound by taking precise measurements of the sound wave at frequent intervals (see Figure 10). During the recognition stage, the computer must identify what has been said. In this context, it starts analyzing the data also known as waves (obtained from the first step) and comparing it with already stored data of other words to identify what the user said. During the communication stage, the computer acts upon the translated input. Figure 10: Speech recognition process Speech (/spitʃ/) Recognition (/ˌrɛkəgˈnɪʃən/) Speech recognition develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It allows, for instance, hands-free control of various devices and equipment and automatic voice translation. ADC: Analog-to-Digital Converter (/kənˈvɜrtər/) An electronic integrated circuit that translate analog signals into digital values for use in processing and control systems, for example, when using the voice recorder of our mobile phones, the ADC will translate our voices as analog signals to digital data that can be recognized, saved and processed by our mobile phones. Story 4: AI Voice Responders Help Call Centers During COVID-19 An AI Voice Responder, as shown in Figure 11, provides a fast and cost-effective way for organizations to better manage various call center needs and maintain a high level of customer service during the pandemic. The AI-enabled solution works by quickly answering the customer's call without making the customer wait. It can also automatically classify calls and resolve common problems without any manual intervention, and classify calls based on subject and urgency, so companies can prioritize follow-up issues to solve more complex issues. As the measures to deal with the new coronavirus pandemic have led to the temporary closure of some mission-critical call centers around the world, consumers are facing long waits as companies struggle to cope with the surge in call volume. This is where the artificial intelligence voice reactor comes to the rescue and diverts high call volumes and answers common questions, quickly solving common support problems without a live agent. For example, the artificial intelligence outbound services of Baidu and iFlytek, as leading providers of artificial intelligence services, can benefit as call centers that are under tremendous pressure due to the novel coronavirus pandemic. At present, the company’s customer service dialogue AI platform can immediately solve problems over the phone, improve customer experiences and reduce costs. Unlike previous generations of IVRs (Interactive Voice Responses), voice responders can understand natural language and enable callers to talk as if they were talking to a living agent. The IVR system accepts mixed voice phone input and key-key keyboard selection, and provides related responses in the form of voice, fax, call back, email and other contact methods. On the other hand, artificial intelligence voice responders are used to help users solve basic hardware problems of commercial products and replace the affected offshore call centers. In addition, voice AI solutions ask questions to identify problems, provide relevant solutions through text, and follow up if the problem is not resolved. Figure 11. AI voice responder process Story 5: Using psychological consultant robot during COVID-19 Two middle school students Thomas and Lee are talking the news released by Carnegie Mellon University (See Figure 12). \"Did you hear that Carnegie Mellon University is working on COVID-19 detection in human voice?\" \"Ah! Isn't that possible?\" \"Don't put limits on the technology. Imagine that if it works, it's certainly better to reduce the risk of infection when people go out to get tested.\" “Yeah. Looking forward to it”. It determines the probability of a user being infected by analyzing his/her voice and comparing it with the voice characteristics of people who are infected with the COVID-19. Sure, until now this application is not a diagnostic system\" and has not been approved by the FDA or CDC and therefore it should not be used as a substitute for medical examination by a health professional. Figure 12. Graphic of Carnegie Mellon Voice detector © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/2.3 Hands-on learning experience Face detection.html":{"url":"content/2.3 Hands-on learning experience Face detection.html","title":"2.3 Hands-on learning experience: Face detection","keywords":"","body":"2.3 Hands-on learning experience: Face detection This section will use a widely popular face detection and manipulation library face-recognition by Adam Geitgey. The images are customized with different colors and border shapes around the detected faces. First, import the useful libraries to our python code. import PIL.Image import PIL.ImageDraw import face_recognition Please select the image name SchoolKids.jpg (you can pick up any image) in the same folder as the code file or else give the proper path of the image. The selected image would load by the load_image_file() method from the face_recognition library which will convert it into a NumPy array of that image. We can then assign it to the variable name given_image. Then assign it to the variable name given_image. given_image = face_recognition.load_image_file('SchoolKids.jpg') Using face_locations() method from the same library, we will count the number of faces in the given_image and will print the length of total faces found in the image. face_locations = face_recognition.face_locations(given_image) number_of_faces = len(face_locations) print(\"We found {} face(s) in this image.\".format(number_of_faces)) Accordingly, to draw any shape on the image, we will convert the image to the Pillow library object using fromarray() method from PIL.Image. pil_image = PIL.Image.fromarray(given_image) Then, we will run a for-in loop to print four pixel locations such as top, left, bottom & right of the detected faces. for face_location in face_locations: top, left, bottom, right = face_location print(\"A face is detected at pixel location Top: {}, Left: {}, Bottom: {}, --Right:{}\".format(top, left, bottom, right)) We will draw a green color rectangle box with width 10 around the faces. draw = PIL.ImageDraw.Draw(pil_image) draw.rectangle([left, top, right, bottom],outline=\"green\", width=10) Now, just use the variable pil_image to display our new image with detected faces using a rectangular border around them. pil_image.show() The new temporary image will be open automatically on your computer (if everything is set up correctly). It should be something like Figure 13. Figure 13. Example of face detection within a given picture If you run the above file, and everything goes fine, you will get the below output at the console of your editor: We found 5 face(s) in this image. A face is detected at pixel location Top: 1454, Left: 3451, Bottom: 1775, Right: 3130 A face is detected at pixel location Top: 1784, Left: 1904, Bottom: 1939, Right: 1749 A face is detected at pixel location Top: 1818, Left: 2351, Bottom: 1973, Right: 2196 A face is detected at pixel location Top: 1830, Left: 1529, Bottom: 1959, Right: 1400 A face is detected at pixel location Top: 1878, Left: 2445, Bottom: 1967, Right: 2355 Test Test the code below with username yuanzhuo and password yuanzhuo. Please choose kernel conda-yuanzhuo. Practice more on Yuanzhuo Online Code Platform Quiz Please select the incorrect statement:\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"3ea2f500125e84c350016a97cf8f533865c3887f\"}\" data-id=\"3ea2f500125e84c350016a97cf8f533865c3887f\" class=\"mcqBox gitQuestion\">Please select the incorrect statement: A. B. C. D. SubmitHint What does facial recognition do?\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"521ea6449b4d72413143c0cb5877cb7a726905ad\"}\" data-id=\"521ea6449b4d72413143c0cb5877cb7a726905ad\" class=\"mcqBox gitQuestion\">What does facial recognition do? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/Chapter 3 Representation and reasoning Can computers think and take decisions like humans.html":{"url":"content/Chapter 3 Representation and reasoning Can computers think and take decisions like humans.html","title":"Chapter 3 Representation and reasoning: Can computers think and take decisions like humans?","keywords":"","body":"Chapter 3 Representation and reasoning: Can computers think and take decisions like humans? We, humans, learn from our experiences so we can start making decisions. For instance, to learn how to ride a bike, we start learning how to use the bicycle pedals, have balance and use the brakes when needed. After several tries, we can decide when to pedal fast and when to coast, when to apply the brakes and when not. With the advances of technology, researchers are now trying to make computers think, do reasoning and make decisions like humans. Knowledge representation and reasoning is the field of AI aimed to make computers intelligent by representing information about the world in a form that they can use to make reasoning and decisions like humans. For instance, we can give computers the location of several places (e.g., restaurants, shops, etc.) as a data point and then computers can do reasoning to select the shortest path from the current location to the location that the user wants to go to. Three methods of reasoning are the deductive, inductive, and abductive approaches. Deductive reasoning starts with the assertion of general rule and proceeds from there to a guaranteed specific conclusion. Deductive reasoning moves from the general rule to the specific application: In deductive reasoning, if the original assertions are true, then the conclusion must also be true. For example, math is deductive: if x = 2and if y = 5then 3x + y = 11 Inductive reasoning begins with observations that are specific and limited in scope, and proceeds to a generalized conclusion that is likely, but not certain, in light of accumulated evidence. You could say that inductive reasoning moves from the specific to the general. For example, Paul always leaves his home to go to school at 7:00 AM, and he is always on time. Paul then assumes that if he leaves at 7:00 AM for school today, he will be on time. Abductive reasoning typically begins with an incomplete set of observations and proceeds to the likeliest possible explanation for the set. Abductive reasoning yields the kind of daily decision-making that does its best with the information at hand, which often is incomplete. For example: Premise 1: You arrived home and were surprised that the front door was open (X)Premise 2: However, if your son had arrived home before you, this would be unsurprising (If Y, then unsurprisingly X)Premise 3: Therefore, it is reasonable to conclude that your son opened the door. (therefore, presumably Z). © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/3.1 Utilizing medical clinic diagnosis during COVID-19.html":{"url":"content/3.1 Utilizing medical clinic diagnosis during COVID-19.html","title":"3.1 Utilizing medical clinic diagnosis during COVID-19","keywords":"","body":"3.1 Utilizing medical clinic diagnosis during COVID-19 In the past, doctors needed long-term training to conduct professional diagnosis. Nowadays, researchers are making computers smart by making them do reasoning and make decisions, especially for medical diagnosis and treatment during COVID-19. Now, through the latest artificial intelligence identification system, we can diagnose the CT image of patients, and analyze the human cells infected by pathogens, so that in hospitals where medical experts and equipment are insufficient, we can also diagnose the epidemic situation in an emergency. First of all, AI is used to perform basic screening and judgment, and then doctors can do control and correction, to guarantee the safety of the patients and improve the time to treatment for the patients. Story 6: Intelligent chest evaluation system of COVID-19 The new chest computed tomography (CT) coronavirus pneumonia (see Figure 14) is an intelligent evaluation system. It can quickly screen suspected patients and assist medical institutions to quickly shunt patients. It includes the following features: Intelligent detection: the traditional method of detecting lesion areas requires doctors to manually outline the ROI, which is inefficient and difficult to promote, while the use of artificial intelligence can achieve rapid automatic detection of lesions, greatly improving efficiency. Intelligent analysis: The AI system enables dynamic 4D comparison of the whole lung lesion in CT, and quantitative analysis of the severity of pneumonia in 2-3 seconds. Intelligent follow-up: intelligent follow-up analysis of the patient's disease course, accurate matching of historical images, automatic analysis of disease metastasis and development. Figure 14. CT coronavirus pneumonia Story 7: AI-Based triage and monitoring system predicts spread of coronavirus Perhaps you're wondering if you could get a doctor's diagnosis and treatment recommendations at home to reduce the hospitals' overcrowding? Believe it or not, it is now possible, thanks to AI. Technology startup Diagnostic Robotics (Tel Aviv, Israel) has developed a triage and monitoring system (see Figure 15) to help healthcare providers, payers and government agencies in the fight against coronavirus (COVID-19). What kind of services can they provide? The solution includes remote patient progress monitoring, automated patient queries, provider-facing alerts about high-risk patients, and daily updates about the spread and progress of the disease at a community and regional level. Definitely, more improvement needs to be done to make it more efficient. Figure 15. A Monitoring system of patients during COVID-19 Story 8: AI tool to predict COVID-19 patients “The Patient in room number 3 is showing infection signs, available doctors, please come to this room.” Such announcements are often heard in hospitals, especially during pandemics. Is it possible to predict if a patient will require additional interventions prior to the onset of symptoms, so as to carry out early prevention in order to save more lives? Some hospitals have begun to experiment AI technologies, where these technologies learn from existing data to find similar patterns and then uses those patterns to make predictions about the future. For instance, new algorithms are now being developed to determine which mildly ill patients are likely to become severely ill. In doing so, these algorithms also found some unexpected early clinical signs that predict severe cases of COVID-19. Figure 16. AI tool to predict COVID-19 infection © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/3.2 Augmented Reality consultation during COVID-19.html":{"url":"content/3.2 Augmented Reality consultation during COVID-19.html","title":"3.2 Augmented Reality consultation during COVID-19","keywords":"","body":"3.2 Augmented Reality consultation during COVID-19 Augmented reality and artificial intelligence are distinct technologies, but they can be used together to create unique experiences. In augmented reality, a 3D representation of the world must be constructed to allow digital objects to exist alongside physical ones. Visual data is used along with an accelerometer and gyroscopes to build a map of the world and track movement within it. Most of these tasks are still done using traditional computer vision techniques that make no use of machine learning. Independently, however, AI models have gotten incredibly good at doing many of the things required to build immersive AR experiences. Deep neural networks can detect vertical and horizontal planes, estimate depth and segment images for realistic occlusion, and even infer 3D positions of objects in real-time. Because of these abilities, AI models are replacing some of the more traditional computer vision approaches underpinning AR experiences. Augmented (/ɔːɡˈmɛntɪd/) Reality (/riˈælɪti/) Augmented Reality (AR) is computer-generated content overlaid on a real-world environment. AR hardware comes in many forms, including devices that you can carry, such as handheld displays, and devices you wear, such as headsets, and glasses. Story 9: How AI-Powered Augmented Reality Helps during Pandemics Do you know AR or VR? Have you experienced AR or VR? What do you think of these emerging technologies especially during this pandemic? AR and VR technologies are emerging as effective solutions in this time as they enable people to connect with others virtually. The pandemic has also brought opportunities for telemedicine or telehealth platforms that are able to offer both patients and care providers a different experience while delivering treatment. These technologies provide engagement for the users, patients and doctors. JD Health, a subsidiary of e-commerce giant JD.com, saw a tenfold growth in monthly consultations for its online health platform during the coronavirus epidemic. In addition, a provider of extended reality and therapeutic applications XRHealth is developing VR telehealth support in its response to prevent the spread of the virus. So, as businesses are suffering due to the spread of COVID-19, such immersive technologies are emerging as their rescue solutions helping them to keep sustain and improve their business profitability not only during the pandemic, but also post-crisis era. It is highly recommended that you try out these emerging technologies. Virtual (/ˈvɜrtʃuəl/) Reality (/riˈælɪti/) Virtual Reality (VR) is the use of computer technology to create a simulated environment that is similar or different from the real world. Unlike traditional user interfaces where users see environments on the screen, users will use Head-mounted display (VR glasses) to be within the VR environment and interact with its components. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/3.3 Hands-on learning experience Reasoning using decision trees.html":{"url":"content/3.3 Hands-on learning experience Reasoning using decision trees.html","title":"3.3 Hands-on learning experience: Reasoning using decision trees","keywords":"","body":"3.3 Hands-on learning experience: Reasoning using decision trees Herein, we provided the basic solution to process the data from data web site. The method is to make the decision by decision tree. What is a decision tree? Decision (/dɪˈsɪʒən/) Tree (/tri/) Decision trees are one of the most popular and powerful machine learning algorithms. It is used to determine a set of actions or show a statistical probability. Each branch of the decision tree represents a possible decision, outcome, or reaction. The farthest branches on the tree represent the end results. One of the reasons why decision trees are so powerful is that they can be easily visualized so that a human can understand what is going on. Imagine a flowchart, where each level is a question with a yes or no answer. Eventually an answer will give you a solution to the initial problem. That is a decision tree. Everybody subconsciously uses decision trees all the time for most menial tasks. Decision trees in machine learning take that ability and multiply it to be able to artificially perform complex decision-making tasks. The decision tree analyses a dataset in order to construct a set of rules, or questions, which are used to predict a class. Let us consider a dataset consisting of lots of different animals and some of their characteristics. These characteristics can be used to predict their class. If we take a falcon and a tiger, a question that would split these two animals would be ‘Does this animal have feathers?’ or perhaps ‘Does this animal lay eggs?’. The answer no for either of these questions would lead to the classification of a tiger, whereas yes would be a falcon. These rules can be built up to create a model that can classify complex situations. To extend the animal classification example, consider the scenario of needing to classify a selection of animals into mammals, reptile, or insects. Look at the visualized decision tree (see Figure 17) to see how two simple questions can be used to split the data. These simple questions layered one after another, allow the classification of a wide range of animals. This is the power of decision trees. Now if we give the trained decision tree a new animal, for example a snake, it will classify it. Does a snake have vertebra? Yes. Is a snake cold-blooded? Yes. Therefore, the model will classify it as a reptile, the correct answer! Figure 17. Decision tree to classify animals into mammals, reptile, or insects When a human construct a decision tree, the questions and answers are based on their logic and knowledge. In data science the creation of these rules is usually governed by an algorithm learning which questions to ask by analyzing the entire dataset. To put this into context we will come back to the animal example, the algorithm will look at all the animals to figure out that all animals that do not breathe air are all fish. This mathematically splits the dataset by its class. This creates powerful algorithms that can classify new data into classes in a way that any human can understand. Decision trees can become much more powerful when used as ensembles. Ensembles are clever ways of combining decision trees to create a more powerful model. These ensembles create state of the art machine learning algorithms that can outperform neural networks in some cases. The two most popular ensemble techniques are random forests and gradient boosting. from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image from pydot import graph_from_dot_data import pandas as pd import numpy as np Accordingly, Let's take a look at how we could go about implementing a decision tree classifier in Python. For example, we’ll be working with what has to be the most popular dataset in the field of machine learning, the iris dataset from UC Irvine Machine Learning Repository. The following source codes are parts of full version. Besides, we used the following library as the handy tool. iris = load_iris() X = pd.DataFrame(iris.data, columns=iris.feature_names) y = pd.Categorical.from_codes(iris.target, iris.target_names) In the proceeding section, we will attempt to build a decision tree classifier to determine the kind of flower given its dimensions. X.head() Although, decision trees can handle categorical data, we still encode the targets in terms of digits (i.e. setosa=0, versicolor=1, virginica=2) in order to create a confusion matrix at a later point. Fortunately, the pandas library provides a method for this very purpose. y = pd.get_dummies(y) We’ll want to evaluate the performance of our model. Therefore, we set a quarter of the data aside for testing. X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) Next, we create and train an instance of the DecisionTreeClassifer class. We provide the y values because our model using a supervised machine learning algorithm. dt = DecisionTreeClassifier() dt.fit(X_train, y_train) We can view the actual decision tree produced by our model by running the following block of code. dot_data = StringIO() export_graphviz(dt, out_file=dot_data, feature_names=iris.feature_names) (graph, ) = graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png()) Notice how it provides the Gini impurity, the total number of samples, the classification criteria and the number of samples on the left/right sides. Test Test the code below with username yuanzhuo and password yuanzhuo. Please choose kernel conda-yuanzhuo. Practice more on Yuanzhuo Online Code Platform Tip Gini Impurity is a measurement of the likelihood of an incorrect classification of a new instance of a random variable, if that new instance were randomly classified according to the distribution of class labels from the data set. If you have interesting, please refer the following address.https://bambielli.com/til/2017-10-29-gini-impurity © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/3.4 Hands-on learning experience Visualizing the Covid-19 data.html":{"url":"content/3.4 Hands-on learning experience Visualizing the Covid-19 data.html","title":"3.4 Hands-on learning experience: Visualizing the Covid-19 data","keywords":"","body":"notebooks# 3.4 Hands-on learning experience: Visualizing the Covid-19 data Due to the characteristics of Python, many Internet masters have developed library functions to support various types of applications. In practicing machine learning algorithms, most of the data sources are available via the web, and this time the epidemic data is the same. Thus, the process of reading data by Python can be demonstrated simply as follows, # pd.read_csv is the function to save the csv format file from web url. pd.read_csv('https://github.com/datasets/covid-19/blob/master/data/countries-aggregated.csv ', parse_dates=['Date']) countries = ['Canada', 'Germany', 'United Kingdom', 'US', 'France', 'China'] where pd is the provided library, and the command function is read.csv (URL), i.e., go directly to the URL to capture the web archive (a comma-separated text file), the field name is date, and the countries classified are Canada, Germany, United Kingdom, United States, France and China. Figure 18. The left side is the raw data, the right side is the formatted data after reading, sorted by Date # The definition of graphic colors and styles to present country data in different colors colors = {'Canada':'#045275', 'China':'#089099', 'France':'#7CCBA2', 'Germany':'#FCDE9C', 'US':'#DC3977', 'United Kingdom':'#7C1D6F'} plt.style.use('fivethirtyeight') # Create Visual Appearance, including graphic size, arrangement plot = covid.plot(figsize=(12,8), color=list(colors.values()), linewidth=5, legend=False) According to the description on web page, the Python library provided by the other party can only takes 5 minutes of program training, and the results are shown in Figure 7. The whole process is easy and clearly. Lines of codes are less than 20, less than three lines of codes are used for the data operation, and the rests are handling on the picture design. Figure 19. Visualization of the data Test Test the code below with username yuanzhuo and password yuanzhuo. Please choose kernel conda-yuanzhuo. Practice more on Yuanzhuo Online Code Platform Quiz The approach of reasoning is ( )\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"8244062cc1a7d32a6d8fd78336275756d0347d0f\"}\" data-id=\"8244062cc1a7d32a6d8fd78336275756d0347d0f\" class=\"mcqBox gitQuestion\">The approach of reasoning is ( ) A. B. C. D. SubmitHint How can AI be applied to medical clinic diagnosis during the COVID-19 pandemic?\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"84abc16733dbe3d9c58ece50e8adec8538748f45\"}\" data-id=\"84abc16733dbe3d9c58ece50e8adec8538748f45\" class=\"mcqBox gitQuestion\">How can AI be applied to medical clinic diagnosis during the COVID-19 pandemic? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/Chapter 4 Learning How do computers learn like humans.html":{"url":"content/Chapter 4 Learning How do computers learn like humans.html","title":"Chapter 4 Learning: How do computers learn like humans?","keywords":"","body":"Chapter 4 Learning: How do computers learn like humans? While humans learn from their past experiences, computers can learn from data rather than through explicit programming. This is known as machine learning. Machine learning uses a variety of algorithms that iteratively learn from data to improve, describe data, and predict outcomes. For instance, as shown in Figure 18, in an online shopping website, the machine will learn the preferences or choices of a particular customer by recording the products that he/she has bought or went through. It will then start recommending to the customer based on these preferences. Figure 20. A computer learning about a shopper from his data In machine learning, four types of learning could be implemented: 1.**Supervised learning**: In this learning type, the machine learning model is taught some knowledge in advance so it can predict future instances. To simplify this definition, we want the machine to know if the student X is a hardworking, good or lazy student based on: **(1)** how many learning hours he/she spends per day; **(2)** how many hours he/she watches the TV. As we mentioned, we need to first teach the machine; in this case we have to give it previous knowledge (also known as labeled dataset) about other students, as shown in Table 1. As you can see in the knowledge given in Table 1, the type of student is known (hard working, good, lazy). The machine will first learn from this knowledge. It will then classify any new student (for instance, our student X) based on how many hours, he/she spent learning and watching TV. Table 1. Example of knowledge information (also known as labeled dataset) to classify a student Student Learning hours TV watching hours Type of student Adam 5 1 Hard working Sarra 3 2 Good student Charlie 2 3 Lazy student 2.Unsupervised learning: In this learning type, we do not teach the machine learning model (like in the first case). Hence, the machine will work on unlabeled data and it will classify or cluster this data based on similar patterns or features. 3.Reinforcement learning: In this learning type, an agent will be within an interactive environment and in a specific state. It will then learn from its own actions and experiences by trial and error using feedback from the environment. To simplify this, we take the example of “fetch the ball” game between the dog and its owner (See Figure 19). The dog (agent) will be in the garden with its owner (interactive environment) where the owner throws the ball (state). The dog (agent) has to perform an action which could be running after the ball or not. If the dog fetches the ball (action), its owner (interactive environment) will reward him by giving him food, in this way the dog (agent) will know that he is doing the right action and he should keep doing that. If the dog does not bring the ball (action), its owner will not give him food. In this way, the dog (agent) will know that it is doing the wrong action, and it should go bring the ball (correct action) Figure 21. “Fetch the ball” game between the dog and its owner 4.Deep learning: Deep learning is a specific method of machine learning that incorporates neural networks in successive layers in order to learn from data in an iterative manner. Deep learning is especially useful when you are trying to learn patterns from unstructured data. Just like we have seen above, machine learning can learn and make predictions based on the given data. Therefore, it is important to give the machine: (1) good quality data: which means accurate and correct data that can help the machine takes correct decisions; and, (2) big amount of data which can help the machine learns several information that can help it perform several actions and decisions. To simplify this, we can consider the machine as the “car” and the data as the “fuel” (See Figure 20). So, the car cannot work without the fuel, same for the machine, it cannot work without the data. Also, if we give too much good quality fuel to the car, the engine then will not be harmed and the car can take us on a long trip. Same for the machine, accurate data, will not harm the machine and make it take correct decisions, and too much data will make it take several decisions or predictions. Figure 22. Importance of data for machine learning Computer (/kəmˈpyutər/) data (/ˈdeɪtə, ˈdætə, ˈdɑtə/) Computer data is information processed or stored by a computer. This information can be in different forms, such as text, audio, or image. Computer data is processed by the computer's Central Processing Uunit (CPU) and can be stored on the computer's hard disk or online, on the cloud. There is an urgent need for hospitals and relevant departments at all levels to establish interactive information interfaces and connections, as well as a platform for all parties to collaborate and share information in real time, so that information and data can be shared among medical institutions and between medical institutions and regional administrative departments in accordance with their mandates, providing an effective basis for management and decision-making. In this context, the most important thing is to provide a unified and structured data platform, so that doctors and researchers can easily access to international and updated data. For instance, as shown in Figure 21, COVID-19 surveillance platform was established by Ningbo medical health committee, China in the early 2020, and it could be used to monitor the 4000 medical institutions in Ningbo. All of the data, such confirmed cases, age of infected patients, etc. come from the Yindu Cloud in China. Figure 23. COVID-19 surveillance platform, established by Ningbo medical health committee © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/4.1 Application of machine learning to predict the spread of COVID-19.html":{"url":"content/4.1 Application of machine learning to predict the spread of COVID-19.html","title":"4.1 Application of machine learning to predict the spread of COVID-19","keywords":"","body":"4.1 Application of machine learning to predict the spread of COVID-19 Story 10: AI tool to predict COVID-19 patients \"When will school reopen? What is the evolution of COVID-19? How long will COVID -19 last? How can we know the trend of this pandemic?” Many people are now asking these questions. To answer all these questions and predict how the virus will spread, Tuli et al. (2020) built a machine learning model to make a good advanced prediction of the number of new cases and the dates when the pandemic might end. For example, the model shown in Figure 22 shows curves corresponding to both new cases and deaths across the world. Figure 24. Prediction model about new cases and deaths across the world during COVID-19 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/4.2 Application of machine learning to accelerate healthcare solutions during COVID-19.html":{"url":"content/4.2 Application of machine learning to accelerate healthcare solutions during COVID-19.html","title":"4.2 Application of machine learning to accelerate healthcare solutions during COVID-19","keywords":"","body":"4.2 Application of machine learning to accelerate healthcare solutions during COVID-19 During pandemics, AI can be the best friend of doctors, where computers can be used to speed-up finding medical solutions or vaccines to some diseases. For instance, by using machine learning techniques, it is possible to do a quick screening of billions of chemical compounds quickly to find relevant medicine candidates. Story 11: Application of machine learning to help accelerate the discovery of medicine for treating COVID-19 Scientist can now apply machine learning to accelerate the process of finding medicine for COVID-19. For example, Oxford-based Exscientia is now using machine learning techniques to accelerate the process of finding effective medicine. Specifically, AI can learn the structure of DNA and the virus efficiently. It can then quickly analyze big data related to medicine information in order to identify those medicines which have the potential of treating COVID-19. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/4.3 Hands-on learning experience training the machine to perform an action.html":{"url":"content/4.3 Hands-on learning experience training the machine to perform an action.html","title":"4.3 Hands-on learning experience: training the machine to perform an action","keywords":"","body":"4.3 Hands-on learning experience: training the machine to perform an action Convolution Neural Network (CNNs) are largely applied in the domain of computer vision and have been highly successful in achieving state of the art performance on various test cases. The hidden layers in a CNN are generally convolution and pooling (downsampling) layers. In each convolution layer, we take a filter of a small size and move that filter across the image and perform convolution operations. Convolution operations are nothing but element-wise matrix multiplication between the filter values and the pixels in the image and the resultant values are summed. CNN: Convolution (/ˌkɒnvəˈluʃən/) Neural (/ˈnʊərəl/) Network (/ ˈnɛtˌwɜrk/) CNN is a convolutional neural network is a feed-forward neural network that is generally used to analyze visual images by processing data with grid-like topology. It’s also known as a ConvNet. Generally, a convolutional neural network is used to detect and classify objects in an image. CNN is also computationally efficient. It uses special convolution and pooling operations and performs parameter sharing. This enables CNN models to run on any device, making them universally attractive. All in this sounds like pure magic. We are dealing with a very powerful and efficient model which performs automatic feature extraction to achieve superhuman accuracy. All CNN models follow a similar architecture, as shown in Figure 25. FFigure 25. CNN architecture Now, let’s move on to pooling layers. Pooling layers are used to downsize the image. The image would contain a lot of pixel values and it is typically easy for the network to learn the features if the image size is progressively reduced. Pooling layers help in reducing the number of parameters required and hence, this reduces the computation required. Pooling also helps in avoiding overfitting. There are two types of pooling operation that could be done: Max Pooling — Selecting the maximum value Average Pooling — Sum all of the values and dividing it by the total number of values Before we start coding, I would like to let you know that the dataset we are going to use is the MNIST digits dataset and we are going to use the Keras library with a Tensorflow backend for building the model. Ok, enough. Let’s do some coding. import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2Dimport numpy as np First, let us do some necessary imports. The keras library helps us build our convolutional neural network. We download the mnist dataset through keras. We import a sequential model, which is a pre-built keras model where you can add the layers. We introduce the convolution and pooling layers. We also import dense layers as they are used to predict the labels. The dropout layer reduces overfitting and the flattening layer expands a three-dimensional vector into a one-dimensional vector. Finally, we import numpy for matrix operations. batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(60000,28,28,1) x_test = x_test.reshape(10000,28,28,1) print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) Most of the statements in the above code would be trivial, I would just explain some lines of the code. We reshape x_train and x_test because our CNN accepts only a four-dimensional vector. The value 60000 represents the number of images in the training data, 28 represents the image size and one represents the number of channels. The number of channels is set to one if the image is in grayscale and if the image is in RGB format, the number of channels is set to three. We also convert our target values into binary class matrices. To know what binary class matrices look like take a look at the example below. model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1))) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) We build a sequential model and add convolutional layers and max pooling layers to it. We also add dropout layers in between, dropout randomly switches off some neurons in the network which forces the data to find new paths. Therefore, this reduces overfitting. We add dense layers at the end which are used for class prediction(0–9). model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1]) We now compile the model with a categorical cross entropy loss function, Adadelta optimizer and an accuracy metric. We then fit the dataset to the model, i.e we train the model for 12 epochs. After training the model, we evaluate the loss and accuracy of the model on the test data and print it (see Figure 24). Figure 26. The obtained output results Test Test the code below with username yuanzhuo and password yuanzhuo. Please choose kernel conda-yuanzhuo-tf-chapter4. Practice more on Yuanzhuo Online Code Platform Quiz How does deep learning work?\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"d10dad436a7a3a3dc54d44a4de985cebbbec1786\"}\" data-id=\"d10dad436a7a3a3dc54d44a4de985cebbbec1786\" class=\"mcqBox gitQuestion\">How does deep learning work? A. B. C. D. SubmitHint Which statement about Convolution Neural Network (CNN) is not true?\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"a13a76a2cae3fc0032d2324cf0841ad2d3d95713\"}\" data-id=\"a13a76a2cae3fc0032d2324cf0841ad2d3d95713\" class=\"mcqBox gitQuestion\">Which statement about Convolution Neural Network (CNN) is not true? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/Chapter 5 Natural interaction Can computers understand humans and talk to them.html":{"url":"content/Chapter 5 Natural interaction Can computers understand humans and talk to them.html","title":"Chapter 5 Natural interaction: Can computers understand humans and talk to them?","keywords":"","body":"Chapter 5 Natural interaction: Can computers understand humans and talk to them? AI is now used to make machines intelligent and interact and communicate like humans. For example, we can mention the case of Siri which is a smart virtual assistant developed by Apple Inc (see several examples in Figure 27). It uses voice queries and a natural-language user interface to answer questions, make recommendations, and perform actions by delegating requests to a set of internet services. Figure 27. Examples of smart virtual assistants that can interact with humans To conduct natural language interaction and communicate with humans, a machine conducts the following steps: (1) take the human input, such as speech; (2) analyze the input (speech) to understand what a person is trying to say; (3) do the reasoning process to provide an accurate answer or perform a task; and, (4) perform the action, by answering the user back or executing a specific task. To deliver an intelligent, humanlike experience, a machine should use a number of Natural Language Processing (NLP) principles and technologies. For instance, Figure 28 shows a communication scenario between a human and a virtual assistant to play a specific music. Figure 28. A communication scenario between a human and a virtual assistant to play a specific music NLP is defined as the application of computational techniques to the analysis and synthesis of natural language and speech. In other words: the use of different techniques from computer science (algorithms) to understand and manipulate human language and speech. NLP has the following two main components: Natural Language Understanding (NLU): It revolves around machine reading comprehension. This is an AI-hard problem. An NLU system needs the following components: (1) Lexicon, Parser, and Grammar rules; and, (2) Semantic theory to guide comprehension. Natural Language Generation (NLG) is concerned with generating natural language. It uses a machine representation system like a knowledge base or a logical form. You can think of it as a translator between data and natural language representation; this is the opposite of NLU. This involves three tasks: (1) Text Planning- To extract relevant content from the knowledge base; (2) Sentence Planning- To choose appropriate words, form meaningful phrases, and set sentence tone; and, (3) Text Realization- To map the sentence plan into sentence structure. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/5.1 Smart chatbots to answer users’ inquiries about COVID-19.html":{"url":"content/5.1 Smart chatbots to answer users’ inquiries about COVID-19.html","title":"5.1 Smart chatbots to answer users’ inquiries about COVID-19","keywords":"","body":"5.1 Smart chatbots to answer users’ inquiries about COVID-19 A chatbot is a computer program that allows humans to interact with technology using a variety of input methods such as voice, text, gesture and touch. It is known by several names, including as a conversational AI bot, AI chatbot, AI assistant, intelligent virtual assistant, virtual customer assistant, digital assistant, conversational agent, virtual agent, conversational interface and more, chatbots are growing in popularity. The chatbot uses NLP (see previous section) to analyze the text input, considers the best response and delivers that back to the user. For instance, it is possible to try the chatbot Elbot (https://www.elbot.com/). Smart chatbots, also known as AI chatbots, should have the following capabilities. Intelligent Understanding is more than just correctly interpreting the user’s request. It’s about being able to instantly merge other pieces of information such as geolocation or previous preferences into the conversation to deliver a more complete answer. Memory allows a chatbot to remember pertinent details to reuse during a conversation or implicitly learn about a person to be reused later. For example, a mobile assistant might learn through previous requests and responses that the user clearly prefers Italian cuisine and so will use this information when asked for restaurant recommendations in future. Sentiment analysis enables a chatbot to understand the mood of the customer and the strength of that feeling. This is particularly important in customer service type applications where it can be linked to complaint escalation flows, but also can be used in other more trivial ways such as choosing which songs to play upon request. Personality can make a huge difference to engagement and the trust users place in the chatbot. While some companies chose to reinforce it using avatars, personality can easily be conveyed in the conversation alone. Persistence allows people to pick up a conversation where they last left off, even if they switch devices, making for a more natural and seamless user experience. Topic switching enables the user to veer off onto another subject, such as asking about payment methods while enquiring if a product is in stock. The chatbot should also then be capable of bringing the user back on track if the primary intent is not reached. Story 12: Human-Robot to clean hospitals during COVID-19 Can you guess what the robot is doing (see Figure 29)? Yes, the robot is cleaning at the city state's Alexandra Hospital-Singapore. The robot can stop automatically when someone approaches from the opposite direction. It is popular at the hospital and some patients even wave at her. Remember to say “hello” to the robot when you see it. Figure 29. A robot cleaner at hospitals during COVID-19 Story 13: Smart chatbots to fight against the COVID-19 COVID-19 Have you thought about talking with a chatbot which can solve your health issues as well as other emergency questions? As shown in Figure 30, the Centers for Disease Control and Prevention (CDC) has developed the Chabot “Clara” to keep people safe during this pandemic. Figure 30. The smart chatbot “Clara” © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/5.2 Utilizing natural language processing to analyze and understand the online public’s opinions and concerns towards COVID-19.html":{"url":"content/5.2 Utilizing natural language processing to analyze and understand the online public’s opinions and concerns towards COVID-19.html","title":"5.2 Utilizing natural language processing to analyze and understand the online public’s opinions and concerns towards COVID-19","keywords":"","body":"5.2 Utilizing natural language processing to analyze and understand the online public’s opinions and concerns towards COVID-19 Along with the coronavirus pandemic, another crisis appeared in the form of large-scale fear and panic, and incomplete and often inaccurate information aggravated the phenomenon. Therefore, there is an urgent need to solve and better understand the information crisis of the new coronavirus pandemic and to measure public sentiment in order to implement appropriate information transmission and policy decisions. Using natural language processing, researchers can monitor popular online comment boards to better understand public concerns during the novel coronavirus pandemic. Public health officials can use natural language manipulation technology to track the topic of COVID-19 that has surged in interest on online forums. These insights can help policy makers understand public health/organizational concerns and priorities, while reducing the spread of misinformation. Real-time analysis of public response can make people aware of changes in public priorities, fluctuations in health conditions, and the adoption of public health measures, all of which will have an impact on individual and group levels of health. Story 14: COVID-19 Public Sentiment Insights and Machine Learning for Tweets Classification How people feel during this pandemic? This is a very complicated task as billions of people exist worldwide. However, nothing is impossible with AI. On June 11, 2020, a study by the University of Charleston determined public sentiment related to the pandemic through the Twitter and internal resistance health statistics software of the Coronavirus Group Health Organization, and sentiment analysis software. Through the use of descriptive text analysis and necessary text data visualization technology, they have proved that over time, as the new coronavirus pneumonia in the United States approaches its peak, the development of fear also reaches its peak (see Figures 31 and 32). Figure 31: An instance of word cloud in twitter data Figure 32: A couple of word cloud instances © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/5.3 Hands-on learning experience Sentence tokenization.html":{"url":"content/5.3 Hands-on learning experience Sentence tokenization.html","title":"5.3 Hands-on learning experience: Sentence tokenization","keywords":"","body":"5.3 Hands-on learning experience: Sentence tokenization When we talk about the natural language processing, we can learn how to handle the sentence tokenization and formulate document vector firstly. Sentence tokenization (also called sentence segmentation) is the problem of dividing a string of written language into its component sentences. The idea here seems very simple. In English and some other languages, we can split apart the sentences whenever we see a punctuation mark. However, even in English, this problem is not trivial due to the use of full stop character for abbreviations. When processing plain text, tables of abbreviations that contain periods can help us to prevent incorrect assignment of sentence boundaries. In many cases, we use libraries to do that job for us, so don’t worry too much for the details for now. For example, let’s look a piece of text about a famous board game called backgammon. It's “Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.” To apply a sentence tokenization with NLTK we can use the nltk.sent_tokenize function. text = \"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\" sentences = nltk.sent_tokenize(text) for sentence in sentences: print(sentence) print() As an output, we get the three component sentences separately. Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice. Accordingly, we can learn how to process bag-of-word and count the document vector. The bag-of-words model is a popular and simple feature extraction technique used when we work with text. It describes the occurrence of each word within a document. To use this model, we need to: Design a vocabulary of known words (also called tokens) Choose a measure of the presence of known words Any information about the order or structure of words is discarded. That’s why it’s called a bag of words. This model is trying to understand whether a known word occurs in a document, but don’t know where is that word in the document. The intuition is that similar documents have similar contents. Also, via the content, we can learn something about the meaning of the document. There are two steps. 1. Load the Data We have a reviews.txt file, it is our data and we want to load it as an array. The file content is: I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it. To achieve this we can simply read the file and split it by lines. with open(\"simple movie reviews.txt\", \"r\") as file: documents = file.read().splitlines() print(documents) The output is 'I like this movie, it's funny.', 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.' 2. Design the Vocabulary Let’s get all the unique words from the four loaded sentences ignoring the case, punctuation, and one-character tokens. These words will be our vocabulary (known words). Thus, we need to score the words in each document. The task here is to convert each raw text into a vector of numbers. The simplest scoring method is to mark the presence of words with one for present and zero for absence. Now, let’s see how we can create a bag-of-words model using the mentioned above CountVectorizer class. # Import the libraries we need from sklearn.feature_extraction.text import CountVectorizerimport pandas as pd # Step 2. Design the Vocabulary # The default token pattern removes tokens of a single character. That's why we don't have the \"I\" and \"s\" tokens in the output count_vectorizer = CountVectorizer() # Step 3. Create the Bag-of-Words Model bag_of_words = count_vectorizer.fit_transform(documents) # Show the Bag-of-Words Model as a pandas DataFrame feature_names = count_vectorizer.get_feature_names() pd.DataFrame(bag_of_words.toarray(), columns = feature_names) Our output is shown as follows, We can compare to our text content, this learning can be denoted as the basic introduction of natural language processing. I like this movie, it's funny.I hate this movie.This was awesome! I like it.Nice one. I love it. Test Test the code below with username yuanzhuo and password yuanzhuo. Please choose kernel conda-yuanzhuo. Practice more on Yuanzhuo Online Code Platform Quiz Please select the appropriate example that utilizes Natural Language Process (NLP) in fighting COVID-19 pandemic.\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"e37d1cf63b1b1be0438e4be1494da53e01397081\"}\" data-id=\"e37d1cf63b1b1be0438e4be1494da53e01397081\" class=\"mcqBox gitQuestion\">Please select the appropriate example that utilizes Natural Language Process (NLP) in fighting COVID-19 pandemic. A. B. C. D. SubmitHint What are the main components of Natural Language Process (NLP)?\\n\",\"hint\":\"Try Again ... -->\",\"count\":4,\"id\":\"4c45b34a4807daa5cb04bce05b21aeab510ea08a\"}\" data-id=\"4c45b34a4807daa5cb04bce05b21aeab510ea08a\" class=\"mcqBox gitQuestion\">What are the main components of Natural Language Process (NLP)? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/Chapter 6 Social Impact How AI will impact your life.html":{"url":"content/Chapter 6 Social Impact How AI will impact your life.html","title":"Chapter 6 Social Impact: How AI will impact your life?","keywords":"","body":"Chapter 6 Social Impact: How AI will impact your life? Artificial Intelligence (AI) may have good impact on societies, ecosystems, and human lives, including the human mind, in part because of the new ways in which it influences human thinking and decision-making, and affects education, science, culture, and communication and information. AI systems can be of great service to humanity, but also raises fundamental concerns. For instance, we can talk about artificial stupidity, racist robots, discrimination, job loss etc. The following AI examples can be found that someone should know and consider while developing AI-based solutions. Inaccurate data while training AI systems can lead to inaccurate or unfair decisions for some people. For instance, the system may not detect that someone is infected with COVID-19 when he/she is infected. This can put his/her life and the life of others in danger. AI systems should consider the privacy of persons (patients) while treating them in order to keep their information safe and protect their private lives. The data generated by AI systems can be stored in different servers (e.g. hospital servers, institution servers, etc.), therefore someone may ask if this data belongs to the person (patient) since the system used his/her data, or to the developer/company because it developed the system or to the third party (hospitals, institutions, etc.) since they provided the servers for data collection and processing. Data ownership is a big issue in the field of AI that should be considered. Transparency of how AI systems work, including algorithms, data collection and processing is another issue that should be considered. As shown in this book, AI adoption, especially in health care, is very useful, but still complex due to the social and ethical issues presented above. Whether AI is good or bad can be examined from several perspectives. Therefore, it is crucial to keep in mind these issues while analyzing the broader societal issues at play. It is important need to keep learning and stay informed in order to make good decisions for our future. Furthermore, it is clearly that AI and other emerging technologies, such as robotics, will take over several jobs in the future to make the work automated and faster (Internet of Business, n.d.). However, AI will also open up new opportunities for new jobs that did not exist before. These jobs will require new skills and new knowledge that were not needed long time ago, such as Python, React (web), Angular, machine learning, and Docker (Columbus, 2019). It is seen that several institutions and schools are now updating their curriculum to keep with AI technologies. Therefore, it is very important to keep learning about AI and its related technologies for a better future career. Quiz Please select the correct statement:\\n\",\"hint\":\"Poor Pluto ... -->\",\"count\":4,\"id\":\"ea01bc37e0374eb5d1178e7bbb29239fd9fd3c14\"}\" data-id=\"ea01bc37e0374eb5d1178e7bbb29239fd9fd3c14\" class=\"mcqBox gitQuestion\">Please select the correct statement: A. B. C. D. SubmitHint What changes will not be brought by AI?\\n\",\"hint\":\"Poor Pluto ... -->\",\"count\":4,\"id\":\"6315ac9b0f76f8d36b15d47c5730af6b416cdd37\"}\" data-id=\"6315ac9b0f76f8d36b15d47c5730af6b416cdd37\" class=\"mcqBox gitQuestion\">What changes will not be brought by AI? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/Conclusion.html":{"url":"content/Conclusion.html","title":"Conclusion","keywords":"","body":"Conclusion AI is typically presented in Hollywood movies as a human-hating robot in a doomsday scenario. However, in the current COVID-19 pandemic, AI has emerged as a superhero that can save humanity from viruses and greatly reduce the number of deaths globally. AI researchers around the world have, over the past few years, engineered drastically new capabilities in health care, just in time to combat the novel coronavirus. AI has been used to fight the virus in different stages, from screening and diagnosis to vaccine development. With its ability to learn quickly from data related to COVID-19, AI has saved human beings. Physical robots also come in handy. For instance, self-navigating robots have worked to disinfect hospitals, deliver food and medication, and check body temperatures. At airports and train stations, temperature sensors are used to scan crowds for high temperatures. They are also used with a face recognition system, which can pinpoint individuals with a high temperature and whether they are wearing a surgical mask or not. This system is also being used to ensure that citizens are obeying self-quarantine regulations. Particularly, those who broke the laws and left home would get a call from the authorities, presumably after being tracked by the facial recognition system. Therefore, since severe crises are unlikely to disappear, it is important to prepare the young generation for the next pandemic especially in the era of AI. This could be ensured by preparing courses that could familiarize the young generation with AI background as well as its possible tasks and functionalities. In line with this, this reading book presented the basics solutions of AI in a fun and easy way, as well as vivid stories about how AI is used worldwide to prevent the spread of COVID-19. Finally, this reading book presented the AI challenges that should be considered in the future. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/References.html":{"url":"content/References.html","title":"References","keywords":"","body":"References AIMBOT, https://www.ubtrobot.com/cn/products/aimbot Artificial Solutions. (2020). Chatbots: The Definitive Guide. Build Your Own Convolution Neural Network in 5 mins, https://towardsdatascience.com/build-your-own-con-volution-neural-network-in-5-mins-4217c2cf964f Columbus, L. (2019) AI Skills Among The Most In-Demand For 2020. Accessed from: https://www.forbes.com/sites/louiscolumbus/2019/11/27/ai-skills-among-the-most-in-demand-for-2020/#77bbd7d86b44 Decision tree in Python, https://towardsdatascience.com/decision-tree-in-python-b433ae57fb93 Face Detection in just 5 lines of code, https://towardsdatascience.com/face-detection-in-just-5-lines-of-code-5cc6087cb1a9 Graesser, A. C., McNamara, D. S., Louwerse, M. M., & Cai, Z. (2004). Coh-metrix: analysis of text on cohesion and language. Behavior Research Methods, Instruments, & Computers: A Journal of the Psychonomic Society, Inc, 36(2), 193–202. Hygiene-obsessed Singapore deploys robots to keep coronavirus away in Asian Review, https://asia.nikkei.com/Business/Technology/Hygiene-obsessed-Singapore-deploys-robots-to-keep-coronavirus-away https://cvd.lti.cmu.edu, the demonstration of CDC in Carnegie Mellon University Internet of Business. (n.d.). Robotics, A.I will create 58 million jobs, decimate middle-class careers: World Economic Forum. Accessed from: https://internetofbusiness.com/robotics-a-i-will-create-jobs-but-decimate-middle-class-careers-wef/ McNamara, D. S., Graesser, A. C., McCarthy, P. M., & Cai, Z. (2014). Automated Evaluation of Text and Discourse with Coh-Metrix. Cambridge University Press. Tuli, Shreshth, et al. “Predicting the Growth and Trend of COVID-19 Pandemic using Machine Learning and Cloud Computing.” Internet of Things (2020): 100222. The CT evaluation of Carnegie Mellon University, https://www.yitutech.com/ The demonstration of AI-Based Triage and Monitoring System, http://www.diagnosticrobotics.com The AI perdition tool of the conversation, http://theconversation.com The demonstration of AI-Based Triage and Monitoring System, http://www.diagnosticrobotics.com Visualizing COVID-19 Data Beautifully in Python by Nik Piepenbreier, https://towardsdatascience.com/visual-izing-covid-19-data-beautifully-in-python-in-5-minutes-or-less-affc361b2c6a © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/Aboutus.html":{"url":"content/Aboutus.html","title":"About us","keywords":"","body":"About us Youth Artificial Intelligence Innovation Initiative (YAIII) The development and application of intelligent technology represented by artificial intelligence has brought changes in education content, mode, and environment. In order to cope with the opportunities and challenges of education in the era of artificial intelligence (AI), it is better to carry out AI education in primary and secondary schools, and cultivate innovative talents for the future. In this context, Beijing Normal University (BNU) is actively advocating a lot of attention to the education of artificial intelligence and the growth of young people. In 2019, the National Engineering Laboratory for Cyber learning and Intelligent Technology (CIT) and Smart learning Institute of Beijing Normal University (SLI) have officially released the Youth Artificial Intelligence Innovation Initiative (YAIII). YAIII aims to stimulate teenagers’ curiosity and interest, and to raise the capability in developing original and innovative algorithms to solve authentic complex problems by creating the deep linkage between schools and all society. To prepare the young generation for the future of diverse, uncertain, and intelligent world with fundamental digital literacy and survival ability, YAIII intends to explore public service for students and teachers with advanced artificial intelligence in education by creating a collaborative mechanism among schools and all stakeholders. Smart Learning Institute of Beijing Normal University (SLIBNU) Beijing Normal University (BNU) grew out of the Education Department of Imperial University of Peking established in 1902, which initiated teacher training in Chinaâ€™s higher education. After the development for over a century, BNU has become a comprehensive and research-intensive university with its main characteristics of basic disciplines in sciences and humanities, teacher education and educational science. Smart Learning Institute (SLI) is jointly established by Beijing Normal University and a global educational technology company NetDragon Websoft. SLI is a comprehensive experimental platform involving scientific research, technology development, and innovative instruction. SLI focuses on detecting learning patterns powered by ICT, creating smart learning environments and platforms for life-long and life-wide learning, as well as supporting diversified, personalized and differential learning needs for digital learners. International association of smart learning environment (IASLE) The International association of smart learning environments (IASLE) is a cutting-edge professional forum for researchers, academics, practitioners, and industry professionals interested and/or engaged in the reform of the ways of teaching and learning through advancing current learning environments towards smart learning environments. It provides opportunities for discussions and constructive dialogue among various stakeholders on the limitations of existing learning environments, need for reform, innovative uses of emerging pedagogical approaches and technologies, and sharing and promotion of best practices, leading to the evolution, design and implementation of smart learning environments. Arab League's Educational, Cultural and Scientific Organization (ALECSO) The Arab League Educational, Cultural and Scientific Organization (ALECSO) is a Tunis-based specialized institution working under the umbrella of the League of Arab States. It is essentially concerned with the development and coordination of the activities related to education, culture and sciences in the Arab World. It was established by virtue of Article 3 of the Arab Cultural Unity Charter, and was officially announced in Cairo on July 25, 1970. As stated in Article One of its Constitution, ALECSO was established with the aim of promoting Arab intellectual unity through education, culture and sciences, and enhancing the educational, cultural and scientific level in the Arab World so that it can positively contribute to universal civilization. Edmodo Edmodo is an educational technology company offering a communication, collaboration, and coaching platform to K-12 schools and teachers. The Edmodo network enables teachers to share content, distribute quizzes, assignments, and manage communication with students, colleagues, and parents. Edmodo is very teacher-centric in their design and philosophy: students and parents can only join Edmodo if invited to do so by a teacher. Teachers and students spend large amounts of time on the platform, both in and out of the classroom. Edmodo is free to use, but it also offers premium services. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-06 "},"content/前言.html":{"url":"content/前言.html","title":"前言","keywords":"","body":"前言 人工智能(AI)作为新兴技术之一，在我们的日常生活中已经被广泛地应用于包括教育、医疗、金融等不同领域。然而，尽管人工智能被媒体频繁提及，人们对其的了解仍然不足。如今，青少年成长在智能环境中，他们与机器人、平板电脑等智能设备互动，科技素养对他们来说尤为重要。随着青少年们对人工智能技术的接触和了解，他们对这些设备的使用会变得更加缜密和细致。因此，必须从青少年开始普及计算思维和人工智能的思想方法，培养他们对人工智能研究及利用人工智能解决问题的浓厚兴趣。 目前，人们已经提出了一些人工智能解决方案（如机器人、模式识别等）来应对一些危机，包括当前的新冠肺炎疫情。在人工智能时代，让年轻一代为下一次危机/流行病做好准备是非常重要的。下一代对人工智能技术了解的越多，他们就越有可能开发出智能解决方案，为处于危机中的人类服务，并维持包括经济、教育和健康活动在内的多项重要活动正常运行。 基于上述背景，读本以轻松有趣的方式向9至15岁的青少年介绍人工智能。它用讲故事的方式介绍了一些为了对抗流行病而开发的、基于人工智能的解决方案。此外，读本还通过向青少年们展示可以在互动编程环境上使用和实现的简单编程代码，来呈现关于人工智能的实践学习经验。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/致谢.html":{"url":"content/致谢.html","title":"致谢","keywords":"","body":"致谢 读本撰写过程中，得到了很多人的帮助。非常感谢他们为进行研究和编写内容所付出的辛勤工作。没有他们的帮助，读本就不可能完成。 我们要感谢几位研究人员，他们为读本的内容开发和网络研讨做了大量的工作，他们是：张定文，庄榕霞，周伟，任众，王君秀，高博俊，蔡臻煜，楼贤拓，施依宏，赵仲琳，宋琦琪、刘佳佳，宿金超，Jody Cockroft，蔡志强。还要感谢各国的厂商为了本手册提供他们宝贵的产品资料，包括了中国的科大讯飞、宜硕网络、依图医疗、优必选科技、北京亮亮视野科技、医渡云医疗人工智能技术公司、丁香园、浙江大华科技、深圳大疆创新科技，以及towardsdatascience.com 网页上的数据资料。 同时也感谢北京师范大学智慧学习研究院（SLIBNU）、联合国教科文组织国际农村教育研究与培训中心（UNESCO INRULED）、国际智能学习环境协会（IASLE）、阿拉伯联盟教育文化科学组织（ALECSO）、孟菲斯大学、天津大学和Edmodo等专家在读本编写过程中的专业反馈和建议。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-08 "},"content/第一章什么是人工智能.html":{"url":"content/第一章什么是人工智能.html","title":"第一章 什么是人工智能","keywords":"","body":"第一章 什么是人工智能? 人工智能（AI）不仅仅是像《我，机器人》电影中的机器人所表现的那样（见图1)，它的范围比这更大，是计算机科学和工程的研究领域。现在，它已经成为我们生活的一部分。人工智能有很多不同的类型。AI让计算机等机器变得聪明，并可以模仿人类的行为。 人工智能 由人们制造或生产的东西，通常是自然事物的复制品。并通过计算机来产生学习、思考、理解的能力，以在推理的基础上做出协助人类决定的能力。 图 1.电影中的AI机器人 现在，支持AI的计算机可以像人类一样阅读和书写文本，这种技术被称为自然语言处理（NLP）。事实上，我们无时无刻不在与“机器”进行互动和交流，它们就像我们中的一员。这一技术又叫做AI语音识别。除了语言处理的能力之外，科学家们还让计算机做了只有人类可以完成的事情，我们称之为 \"高阶认知能力\"，比如思考、推理和决策。研究表明，人脑的这些能力主要是源于其神经元（人脑的基本元素）之间的特殊交互方式。科学家们通过实现神经网络之间所谓的 \"大脑式计算\"，使计算机具备这些高阶认知能力。为了实现这些示例，AI使用了多种算法分析数据。图2展示了AI技术如何模仿人类行动的例子。在图2的左边，呈现的是AI直接模仿人类行为的案例，例如语音识别、计算机视觉与模式识别等。 神经网络 由许多相似的部件组成的大系统，如线路、管道、神经等，它们相互连接，共同运作。它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法。 算法 解决问题所需遵循的一系列指令或规则。 数据 所收集的信息，特别是事实或数字，用于研究、发现事物或做出决定。数据可以是不同的格式，如文本、图片或音频。 图2.AI技术模仿人类行动的例子 AI，作为我们语言中的一个常用词，在我们的日常生活中也扮演着至关重要的角色，它们的应用几乎无处不在。例如人工智能在许多游戏中被用于控制非玩家角色（NPC）或机器人。人工智能甚至被用于我们的智能手机中，例如与Siri对话。事实上，几乎所有你在任何时刻看到或做的事情都在某种程度上被人工智能所支持。比如你正在阅读的这个读本，是的，这读本就是一个支持人工智能的计算机程序的产物。人工智能已经成为现代文明每一个产品的整个生命周期的一部分。请随意指出你此时可能看到的任何东西，我们确信AI技术或环境等一定是生产过程的一部分。这些并不限于你玩的游戏或者你使用的智能手机。 当初引入AI的时候，是为了让人类的工作更加高效。在读本中，我们举了一些关于AI的例子和事实。在危机和流行病爆发期间，AI实际上正在“拯救”人类的生命，比如新冠肺炎疫情。在这种情况下，人工智能可以成为我们的超级英雄，试图通过不同的方式来保护我们的安全。因此，要想真正领会AI，我们需要了解它。通过了解AI，你也有可能成为像孙悟空一样的超级英雄，在未来利用人工智能来拯救生命。然而，作为第一步，我们需要一起了解AI，并学习如何通过它成为超级英雄。因此，读本试图用一种简单而有趣的方式，解释人工智能的基本知识。它还介绍了来自不同国家在新冠肺炎疫情防控阶段应用人工智能的生动故事。 让我们学习这个读本，准备好成为未来的超级英雄吧! 冠状病毒 冠状病毒是一大类病毒，可引起动物或人类疾病。在人类中，已知有几种冠状病毒可引起呼吸道感染，乃至从普通感冒到更严重的疾病，如中东呼吸综合症（MERS）和严重急性呼吸综合症（SARS）。最近发现的冠状病毒引起了冠状病毒病COVID-19。 故事 1: 人工智能的历史 AI的历史可以追溯到一个非常遥远的时代，那时没有智能手机，没有互联网。哲学家们将人类的思维描述为一个符号系统。古希腊人曾有过关于机器人的神话，而埃及人则建立了一些自动化系统（能自己工作的系统），但那时还没有“人工智能”这个词。 1952年，阿瑟·塞缪尔，做出了第一个电脑下棋的游戏程序，也是第一个可以自主学习的电脑程序，这让世界为之惊讶。这台计算机比我们现在所知道的计算机大得多（见图3）。经过几年时间，特别是在1956年，“人工智能”一词在美国新罕布什尔州汉诺威市达特茅斯学院的一次会议上被提出。三年后，麻省理工学院（MIT）人工智能实验室建成。后来，在互联网和智能芯片等新技术的帮助下，人工智能开始变得更加有用，也更加容易被使用。现在，我们在任何地方（比如医院）和我们每天使用的东西（比如智能手机）中，都可以看到人工智能的身影。 符号系统 一个使用符号进行计算和通信的系统。 程序 程序是一组可执行的计算机指令 图3.第一个电脑下棋游戏程序 反思练习 数据挖掘是人工智能的重要组成部分。从“挖掘”这个词，你几乎可以猜到它的含义。如果你了解了采煤或采油的过程，请试着提出你自己对数据挖掘的定义，并与教科书上的数据挖掘定义进行比较。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-15 "},"content/第二章计算机如何像人类一样认识世界.html":{"url":"content/第二章计算机如何像人类一样认识世界.html","title":"第二章 计算机如何像人类一样认识世界?","keywords":"","body":"第二章 计算机如何像人类一样认识世界？ 感知系统是人类和一些动物最重要的能力之一。它是帮助动物（包括人类）认识物理环境的能力，主要与生物物种有关。不同的动物具有不同的感知能力。人类的感知能力是指通过感官看到、听到或意识到周围环境的能力。如图4所示，人类用五官（视觉、听觉、嗅觉、味觉和触觉）来感知世界，而计算机则是模仿或复制人类的智慧，用不同的传感器（摄像头、声音探测器、震动传感器等）来感知世界，与人类的感官相似。让计算机像人类一样 \"看 \"和 \"听 \"，是人工智能的重要成果之一。 图4.人类和计算机如何利用感官与传感器来和外界交互 传感器 传感器是一种监测装置，能够感受到被测量的信息，并能将信息按一定规律转换成电信号或其他所需形式的信息输出。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-15 "},"content/2.1在疫情期间利用人脸识别来确认身份.html":{"url":"content/2.1在疫情期间利用人脸识别来确认身份.html","title":"2.1 在疫情期间,利用人脸识别来确认身份","keywords":"","body":"2.1 在新冠疫情期间，利用人脸识别来确认身份 人脸识别是人类最早拥有的本能之一。婴儿需要从其他面孔中识别出父母，这样他们才能与父母联系起来。在这种情况下，婴儿开始盯着父母的脸看（例如，在喂奶期间），直到他们记住了父母的脸。随后，他们就可以开始看到父母的脸和不熟悉的脸之间的区别。同样，计算机也在模仿人类的行为和智能，它们不使用人类的眼睛，而是使用传感器（摄像头）来识别人脸。面部识别是基于面部的几何特征（眼睛、鼻子、嘴巴的形状以及它们之间的几何关系，即它们之间的距离）。 几何特征 它们是由正方形、三角形或矩形等形状组成的视觉特征。 而在目前常用的人脸识别系统中，人脸识别过程包括以下四个步骤（请参考图5-a和5-b）， 人脸检测：在图像中找到一个或多个人脸，并用边界框做标记。 人脸对齐：归一化人脸，使其与数据库一致，如几何学和光度学。 特征提取：从人脸中选择可用于识别任务的特征。 人脸识别：将人脸与准备好的数据库中的一个或多个已知人脸进行比较。 图5.(a)人脸检测示意图，（b）人脸检测过程 人脸识别 人脸识别是通过技术来识别人脸的一种方式。人脸识别系统使用生物识别技术从照片或视频中提取出面部特征信息。它将信息与已知面孔的数据库进行比较，以找到匹配的面孔。 故事2：在新冠疫情期间使用机器人进行口罩检测 “你的体温是正常的，请戴上口罩”，AIMBOT说。AIMBOT是一款智能巡逻机器人，它可以报告提问并提醒人们戴口罩，如图6所示。当多人一起进入时，它还可以进行多次人脸检测和口罩识别。它还可以提醒大家不断调整社交距离，以降低感染风险。AIMBOT是如何做到这一点的？即使是人类，也不能只用眼睛来测量自己的体温。这是因为它除了使用可见光双目摄像头（就像人的眼睛一样）外，还使用红外线传感器来识别访客脸上的体温，并判断访客是否戴了口罩。 图6.正在使用的AIMBOT照片 红外线 它是一种肉眼看不到的光，但可以以热的形式感觉到。 故事3：在新冠疫情期间，利用人脸识别进行疫情筛查 冠状病毒传染性强，人被感染后，病毒在人体内有14天左右的潜伏期。所谓 \"潜伏期\"，就是指一个人开始出现发烧、咳嗽等症状之前的时间段。14天的潜伏期意味着一个人在意识到自己感染病毒之前，可能已经感染了整整两个星期。你可能会担心，并问自己：\"我怎么知道我身边是否有受感染的人？尤其是在他们没有任何症状的情况下？有多少人和他们密切接触？\"人们的移动轨迹数据可以告诉我们! 轨迹数据可以告诉你，患者去过哪里，你是否去过那里。比如，北京健康宝小程序通过摄像头检测人脸，随后，它就会显示出这个人的当前状态。如图7所示，绿色字样表示此人健康状况良好，黄色字样表示此人应该在家隔离。国内很多超市、公园等公共场所只允许健康宝检测正常的人进入这些场所，以保护更多的人。 图7.北京健康宝APP 潜伏期 从有害细菌或病毒进入人或动物、植物体内，到出现疾病症状的时间段。 移动轨迹数据 显示某人或某物从一个地方移动到另一个地方的行经路径的数据。 但AI也不是万能，在以下的状况会使计算机难以识别人脸。 姿势变化：人类有时很难识别他人，例如，当他们从不同角度看朋友时，朋友的头部运动，可以用自我中心旋转角度来描述，即俯仰、滚动和偏航，或者摄像机改变视角，都可能导致面部外观或形状的重大变化，并产生个体差异变化，使计算机难以跨姿势自动识别面部。 面部表情的变化：一个人做出不同的面部表情可能会造成更多的差异。一个人可能会因为处于不同的情绪状态（高兴、愤怒、困惑等）而改变自己的面部表情，如图8中。 所以，高效自动地识别不同的面部表情对情绪状态的评估和自动人脸识别都很重要。 图8.基于不同情绪状态的面部表情 脸部老化：脸部外观变化的另一个原因可能是人脸老化造成的，如果每次拍摄图像的间隔时间较长，可能会影响整个过程。 不同的照明条件：有时，当天色有点暗时（例如在晚上），人类很难识别他人。同样，明暗变化大也会降低AI识别某个人脸特征的性能。事实上，对于背景或前景的低照度，人脸检测和识别的难度要大得多，因为人脸上可能会出现阴影，即便是人脸图案可能看起来一样，如图9所示。 图9.基于不同灯光位置的阴影变化 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/2.2在疫情期间利用语音识别进行自动电话回应.html":{"url":"content/2.2在疫情期间利用语音识别进行自动电话回应.html","title":"2.2 在疫情期间,利用语音识别进行电话自动应答","keywords":"","body":"2.2 在疫情期间，利用语音识别进行电话自动应答 与上面的例子类似（见2.1节），婴儿在很小的时候就开始听父母的声音，并能认出他们的声音。他们能从自己的声音和陌生人的声音中听出区别，所以他们可能会从父母的声音中获得比陌生人的声音更多的安慰。然而，与人类不同的是，计算机没有让他们听到声音的耳朵，也没有让他们理解这些声音是单词或短语的大脑。因此，它们使用传感器，如语音检测器（就像人类的耳朵一样）来检测语音。具体来说，语音识别主要涉及三个阶段： 预处理阶段：包括将语音转化为计算机可以使用的东西。具体来说，当我们说话时，我们的声音在空气中产生振动。然后，计算机使用模数转换器(ADC)将这种模拟波转化为它能理解的数字数据。为此，它通过频繁地对声波进行精确测量，对声音进行采样和数字化（见图10）。 识别阶段，计算机必须识别出所说的内容。在这种情况下，它开始分析被称为波的数据（从第一步获得），并将其与已经存储的其他单词的数据进行比较，以识别用户所说的内容。 交流阶段，计算机根据翻译后的输入进行操作。 图10.语音识别过程 语音识别 语音识别开发了使计算机能够识别并将口语翻译成文本的方法和技术。例如，它可以实现对各种装置和设备的免提控制和自动语音翻译。 ADC: 模数转换器 一种将模拟信号转化为数字值的电子集成电路，用于处理和控制系统，例如，当我们使用手机的语音记录器时，ADC会将我们的声音作为模拟信号转化为数字数据，以便手机识别、保存和处理。 故事4: 人工智能语音应答器在疫情期间帮助呼叫中心 如图11所示的AI语音应答器，为企业提供了一种快速且经济高效的方式，以更好地管理各种呼叫中心的需求，并在流行病期间保持高水平的客户服务。嵌入人工智能机制的解决方案可以快速接听客户的电话，而不会让客户等待。此外，它还可以在不需要任何人工干预的情况下自动根据主题和紧急程度对呼叫进行分类以及解决常见问题，以便公司能够优先处理后续问题，以解决更复杂的问题。 由于对新型冠状病毒流行病采取的措施，导致全球一些关键业务的呼叫中心暂时关闭，消费者面临着漫长的等待，企业难以应对激增的呼叫量。这时，人工智能语音应答器就能派上用场了，它能分流高呼叫量，并解答常见的问题，在没有真人代理的情况下，快速解决常见的支持问题。 例如，百度和科大讯飞公司作为人工智能服务的领先者，其人工智能外呼服务可以让因新型冠状病毒流行病而面临巨大压力的呼叫中心受益。目前，公司的客服对话人工智能平台可以通过电话立即解决问题，改善客户体验，降低成本。 与前几代IVR（交互式语音应答）不同的是，语音应答器可以理解自然语言，使呼叫者感觉像与活生生的代理人交谈一样。IVR系统接受语音电话输入和按键键盘选择的混合方式，并以语音、传真、回拨、电子邮件等联系方式提供相关的应答。另一方面，人工智能语音应答器用于帮助用户解决商用产品的基本硬件问题，替代受影响的境外呼叫中心。此外，人工智能语音解决方案通过提问的方式发现问题，通过文字的方式提供相关的解决方案，如果问题没有解决，则会进行跟踪。 图11.AI语音应答器流程 故事5：在新冠疫情期间使用心理咨询机器人 两名中学生小明和小红正在谈论美国卡内基梅隆大学发布的新闻（见图12）。“你听说卡内基梅隆大学正在研究人类声音的新冠肺炎检测吗？” “啊！这不可能啊！”“不要给技术设限。试想一下，如果能成功，便可以减少感染风险，而人们出去检测时，当然感染的风险越小越好。”，“好啊，好啊。我很期待”。它通过分析用户的声音，并与感染新冠肺炎的人的声音特征进行对比，来判断用户被感染的概率。当然，到现在为止，这个应用还不是诊断系统，还没有得到美国食品健康管理局或疾病防治中心的批准，因此它不能被用来替代健康专家的体检。 图12.卡内基梅隆语音检测器图解 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/2.3实践学习体验：人脸识别.html":{"url":"content/2.3实践学习体验：人脸识别.html","title":"2.3 实践学习体验：人脸识别","keywords":"","body":"2.3 实践学习体验：人脸识别 本节将使用Adam Geitgey开发的一个广泛使用的人脸检测和操作库face-recognition，用来检测到人脸周围，并可以定制不同颜色和边框形状的图像。首先，将有用的库函数导入到我们的python代码中。 import PIL.Image import PIL.ImageDraw import face_recognition 请在代码文件的同一文件夹中选择名为SchoolKids.jpg的图片(你可以选择任何图片)，或给出图片的正确路径。选定的图像将由face-recognition库的load_image_file()方法加载，该方法将把它转换成该图像的NumPy数组。然后我们可以把它赋值给变量名. given_image = face_recognition.load_image_file('SchoolKids.jpg') 使用同一库中的face_locations()方法，我们将统计given_image中的面孔数量，并打印出在图像中发现的总面孔长度。 face_locations = face_recognition.face_locations(given_image) number_of_faces = len(face_locations) print(\"We found {} face(s) in this image.\".format(number_of_faces)) 相应地，为了在图像上绘制任意形状，我们将使用PIL.Image中的fromarray()方法将图像转换为Pillow库对象。 pil_image = PIL.Image.fromarray(given_image) 然后，我们将运行一个for-in循环来打印检测到的人脸的上、左、下、右四个像素位置。 for face_location in face_locations: top, left, bottom, right = face_location print(\"A face is detected at pixel location Top: {}, Left: {}, Bottom: {}, --Right:{}\".format(top, left, bottom, right)) 我们将在人脸的周围画一个宽度为10的绿色矩形框。 draw = PIL.ImageDraw.Draw(pil_image) draw.rectangle([left, top, right, bottom],outline=\"green\", width=10) 现在，只需使用变量pil_image来显示我们的新图像，检测到的人脸周围使用矩形边框。 pil_image.show() 新的临时图像将在您的计算机上自动打开（如果一切设置正确）。它应该像图13一样。 图13.在给定图片中进行人脸检测的例子 如果你运行上面的文件，一切正常，你将在编辑器的控制台得到下面的输出： We found 5 face(s) in this image. A face is detected at pixel location Top: 1454, Left: 3451, Bottom: 1775, Right: 3130 A face is detected at pixel location Top: 1784, Left: 1904, Bottom: 1939, Right: 1749 A face is detected at pixel location Top: 1818, Left: 2351, Bottom: 1973, Right: 2196 A face is detected at pixel location Top: 1830, Left: 1529, Bottom: 1959, Right: 1400 A face is detected at pixel location Top: 1878, Left: 2445, Bottom: 1967, Right: 2355 测试 请在我们的jupyter服务器上测试代码并进行练习，默认账户名yuanzhuo，默认密码yuanzhuo. 请将kernel设置为conda-yuanzhuo. Yuanzhuo Online Code Platform 测验 请选择不正确的说法：\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"7ef139c5f09465c94bd38755741689b3970c1d97\"}\" data-id=\"7ef139c5f09465c94bd38755741689b3970c1d97\" class=\"mcqBox gitQuestion\">请选择不正确的说法： A. B. C. D. SubmitHint 人脸识别有什么作用？\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"be56793cb312ca712f630c70c278260434a8655f\"}\" data-id=\"be56793cb312ca712f630c70c278260434a8655f\" class=\"mcqBox gitQuestion\">人脸识别有什么作用？ A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/第三章计算机能像人类一样思考吗.html":{"url":"content/第三章计算机能像人类一样思考吗.html","title":"第三章 计算机能像人类一样思考吗","keywords":"","body":"第三章 计算机能像人类一样思考吗？ 人类从经验中学习，这样才能学会如何做决定。例如，为了学会骑自行车，我们从学习如何使用自行车踏板开始，然后学习掌握平衡，并在需要时使用刹车。经过几次尝试，我们可以决定什么时候刹车，什么时候不刹车，什么时候快些刹车，什么时候慢些刹车。随着科技的发展，现在研究人员正试图让计算机像人类一样思考、推理和决策。知识表示和推理是人工智能的一个领域，旨在通过将世界的信息以一种特殊形式表示出来，让计算机能够像人类一样进行推理和决策，从而让计算机变得智能化。例如，我们可以给计算机提供几个地方的位置（如餐厅、商店等）作为数据点，然后计算机就可以进行推理，选择从当前位置到用户想去位置的最短路径。 推理的方法有三种，分别是演绎法、归纳法和溯因法。演绎推理从一般规则的论断出发，逐步推理直至得出可靠的具体结论。演绎推理是从一般规则到具体应用的过程：在演绎推理中，如果最初的断言是真的，那么结论也必须是真的。例如，数学可以通过演绎推理来体现： 如果 x = 2并且如果 y = 5那么 3x + y = 11 归纳推理从具体的、范围有限的观察入手，根据积累的证据，得出可能但不确定的一般化结论。你可以说，归纳推理是从具体到一般的过程。例如，保罗总是在早上7:00离开家去上学，他总是很准时。那么，保罗就会假设，如果他今天早上7:00离开家去上学，他就会准时到校。 溯因推理通常是从一组不完整的观察结果开始，然后进行最可能的解释。溯因推理使得日常决策能够基于手头的信息做到最好，即便这些信息往往是不完整的。比如说： 前提1：你到家后惊讶地发现前门是开着的（X）。前提2： 然而，如果你儿子比你先到家，这就不足为奇了（如果是Y，那么 X 就不足为奇了）。前提3：因此，可以合理断定是你儿子开的门。（因此，推测为Z）。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-08 "},"content/3.1利用疫情数据进行医疗诊断.html":{"url":"content/3.1利用疫情数据进行医疗诊断.html","title":"3.1 利用疫情数据进行医疗诊断","keywords":"","body":"3.1 利用疫情数据进行医疗诊断 过去，医生需要经过长期的培训才能进行专业的诊断。如今，研究人员通过让计算机进行推理和决策，特别是针对新冠肺炎期间的医疗诊断和治疗，来使计算机变得智能化。现在，通过最新的人工智能识别系统，我们可以对患者的新型胸部计算机断层扫描(简称CT)图像进行诊断，对病原体感染的人体细胞进行分析，在医疗专家和设备不足的医院，我们也可以在紧急情况下对疫情进行诊断。首先利用人工智能进行基本的筛查和判断，医生可以在此基础上做控制和纠正，在保证患者安全的同时提高治疗患者的效率。 故事6：新冠肺炎疫情的智能胸腔评估系统 智能胸腔评估系统是针对冠状病毒、新冠肺炎的CT图像（见图14）所建立的一套智能评估系统，主要是由美国卡内基梅隆大学所提供的技术。它可以快速筛查疑似患者，协助医疗机构快速分流患者。包括以下功能： 智能检测：传统检测病变部位的方法需要医生手动勾画，效率低下，难以推广，而利用人工智能可以实现病变部位的快速自动检测，大大提高了效率。 智能分析：人工智能系统可实现CT中全肺病变的动态对比，2-3秒内定量分析肺炎的严重程度。 智能追查：智能随访分析患者病程，精准匹配历史影像，自动分析疾病的转移和发展。 图14.CT冠状病毒肺炎 故事7：基于AI预测新冠疫情的传播情况的分流和监测系统 也许你曾想过，能不能在家里就能得到医生的诊断和治疗建议，以减少医院的拥挤？不管你信不信，现在可以了，这要归功于AI。以色列特拉维夫的科技初创公司Diagnostic Robotics开发了一套分诊和监测系统（见图15），帮助医疗服务提供者、支付方和政府机构对抗冠状病毒。他们能提供什么样的服务呢？该解决方案包括远程对患者进行监测、患者自动查询、面向医疗服务者提供高危患者警报，以及每天定时更新社区和地区层面的疾病传播和进展情况。当然，目前这套系统还需要更多改进来使其更为高效。 图15.新冠疫情期间患者的监测系统 故事8：可预测新冠肺炎患者病情 的AI工具 “3号病房的病人有感染迹象，有空的医生请到本病房来。”这样的广播在医院里经常听到，尤其是在全球性流行病疫情期间。那么有没有可能在患者出现症状之前就预测到患者是否需要额外的干预，从而进行早期预防以挽救更多的生命呢？一些医院已经开始利用人工智能技术进行实验，这些技术可以从现有的数据中学习，找到类似的模式，然后利用这些模式对未来进行预测。例如，现在正在开发新的算法来判断哪些轻症患者有可能成为重症患者。在此过程中，这些算法可能还会发现一些意想不到的早期临床症状，可以预测新冠肺炎的严重病例。主要技术由美国Conversion公司所提供。 图16.AI工具预测新冠肺炎的感染程度 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/3.2基于增强现实技术的新冠肺炎病情咨询.html":{"url":"content/3.2基于增强现实技术的新冠肺炎病情咨询.html","title":"3.2 基于增强现实技术的新冠肺炎病情咨询","keywords":"","body":"3.2 基于增强现实技术的新冠肺炎病情咨询 增强现实（简称AR）和AI是两种不同的技术，但它们也可以一起使用，以创造独特的体验。在增强现实中，必须构建世界的3D表示，以允许数字对象与物理对象并存。视觉数据与加速度计和陀螺仪一起使用，以构建世界地图并跟踪其中的运动。这些任务大多还是使用传统的计算机视觉技术来完成，并没有使用机器学习。 然而，分开来看，AI模型已经在许多构建沉浸式AR体验所需做的事情上变得非常出色。深度神经网络可以检测垂直和水平平面，估计深度并分割图像以实现真实的遮挡，甚至可以实时推断物体的3D位置。基于这些能力，AI模型正在取代一些用于增强AR体验的更传统的计算机视觉方法。 增强现实 增强现实（Augmented Reality，简称AR）是将计算机生成的内容叠加在现实世界的环境中。AR硬件有多种形式，包括你可以携带的设备，如手持显示器，以及你佩戴的设备，如耳机、眼镜。 故事9：AI驱动的增强现实如何在新冠疫情期间提供帮助？ 你了解AR或VR吗？你体验过AR或VR吗？在这次疫情期间，你对这些新兴技术有什么看法？AR和VR技术能够在这个时候作为新兴的有效解决方案，正因为它们能在人与人之间建立虚拟连接。这次疫情也为远程医疗和远程健康平台带来了机会，这些平台不仅能够提供治疗，同时也为患者和护理人员提供了不同的体验，为用户、患者和医生提供了参与感。电商巨头京东的子公司京东健康在疫情期间做了调查，发现其在线健康平台的月咨询量较疫情前增长了10倍。此外，扩展现实和治疗应用的提供商XRHealth正在开发基于VR技术的远程医疗支持，以防止病毒的继续传播。因此，当企业因新冠肺炎的传播而苦不堪言时，沉浸式技术的出现成为他们的救援方案，帮助他们在疫情期间乃至后危机时代保持和提高业务盈利的能力。我们强烈建议你尝试这些新兴技术。 虚拟现实 虚拟现实（Virtual Reality，简称VR）是利用计算机技术创造一个与现实世界相似或不同的模拟环境。与传统的用户界面不同，用户在屏幕上看到的是环境，用户将使用头戴式显示器(VR眼镜)置身于VR环境中，并与环境中的各个组成部分进行互动。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/3.3实践学习体验：使用决策树进行推理.html":{"url":"content/3.3实践学习体验：使用决策树进行推理.html","title":"3.3 实践学习体验：使用决策树进行推理","keywords":"","body":"3.3 实践学习体验：使用决策树进行推理 在此，我们提供了处理数据网站数据的基本解决方案。其方法是通过决策树进行决策。什么是决策树？ 决策树 决策树是最流行、最强大的机器学习算法之一。它用于确定一组行动或显示一个统计概率。决策树的每个分支都代表一个可能的决策、结果或反应。树上最远的分支代表最终结果。 决策树如此强大的原因之一是它可以很容易地可视化，以便人类能够理解正在发生的事情。想象一个流程图，其中每一级都是一个有“是”或“否”答案的问题。最终答案会给你一个初始问题的解决方案。这就是决策树。每个人都会下意识地使用决策树来处理大多数琐碎的任务。机器学习中的决策树能利用甚至成倍放大这种处理问题的能力，去执行人工处理时面临的复杂的决策任务。 决策树对一个数据集进行分析，以构建一组规则或问题，用来预测一个类。让我们考虑一个由很多不同动物和它们的一些特征组成的数据集。这些特征可以用来预测它们的类别。拿一只猎鹰和一只老虎来说，区分这两种动物的问题是 \"这种动物有羽毛吗？\"或者可能是 \"这种动物会下蛋吗？\"。这两个问题的答案都是 \"否\"，就会被归为老虎，而 \"是 \"则是猎鹰。这些规则可以被建立起来，以创建一个可以对复杂情况进行分类的模型。为了扩展动物分类的例子，考虑需要将一组动物分类为哺乳动物、爬行动物或昆虫的场景。想了解如何使用两个简单的问题来分割数据的话，可以看看图17所示的决策树示例图。这些简单的问题一个接一个地层层递进，可以对多种动物进行分类。这就是决策树的威力。现在如果我们给训练好的决策树一个新的动物，比如说蛇，它就会对它进行分类。蛇有脊椎骨吗？有。蛇是冷血动物吗？是的，所以模型会把它分类为爬行动物，这就是正确的答案！ 图17.决策树：将动物分为哺乳动物、爬行动物或昆虫 当人类构建决策树时，问题和答案是基于逻辑和知识的。在数据科学中，这些规则的创建通常是由一个算法来管理的，它通过分析整个数据集来学习要问哪些问题。为了说明这一点，我们再来举动物的例子，算法会查看所有的动物，找出所有不呼吸空气的动物都是鱼。相当于在数学上将数据集按其类别进行了分割。这就创造了强大的算法，可以用任何人都能理解的方式将新数据分类。当多个决策树用来做集成决策时，可以变得更加强大。集成决策是将决策树组合起来创建更强大模型的巧妙方法。这些集成技术创建了最先进的机器学习算法，在某些情况下甚至可以超越神经网络。 from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image from pydot import graph_from_dot_data import pandas as pd import numpy as np 相应地，让我们来看看如何在Python中去实现一个决策树分类器。例如，我们将使用机器学习领域最流行的数据集，即UC Irvine Machine Learning Repository的鸢尾花数据集。首先如上面的代码所示，我们将需要用到的库导入进来。然后，再参照以下代码，调用相应的模块。 iris = load_iris() X = pd.DataFrame(iris.data, columns=iris.feature_names) y = pd.Categorical.from_codes(iris.target, iris. 在接下来的部分，我们将尝试建立一个决策树分类器，来确定给定尺寸的花的种类。用X.head()来显示数据集的前五行内容。 X.head() 虽然决策树可以处理分类数据，但我们仍然需要用数字来对目标进行编码（即setosa=0，versicolor=1，virginica=2），以便在以后创建一个混淆矩阵（也称误差矩阵）。幸运的是，pandas库已经提供了一个这样的方法来达到这个目的。 y = pd.get_dummies(y) 后续我们会评估我们模型的性能。因此，我们留出四分之一的数据进行测试。 X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) 接下来，我们创建并训练一个 DecisionTreeClassifer 类的实例。我们提供y值，因为我们的模型使用的是有监督的机器学习算法。 dt = DecisionTreeClassifier() dt.fit(X_train, y_train) 我们可以通过运行以下代码块来查看我们的模型生成的实际决策树。 dot_data = StringIO() export_graphviz(dt, out_file=dot_data, feature_names=iris.feature_names) (graph, ) = graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png()) 测试 请在我们的jupyter服务器上测试代码并进行练习，默认账户名yuanzhuo，默认密码yuanzhuo. 请将kernel设置为conda-yuanzhuo. Yuanzhuo Online Code Platform © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/3.4实践学习体验：疫情数据的可视化.html":{"url":"content/3.4实践学习体验：疫情数据的可视化.html","title":"3.4 实践学习体验：新冠疫情数据的可视化","keywords":"","body":"3.4 实践学习体验：新冠疫情数据的可视化 由于Python的特性，很多互联网高手都开发了支持各种类型应用的库函数。在实践机器学习算法的过程中，大部分的数据源都可以通过网络获得，这次的流行数据也是如此。因此，用Python读取数据的过程演示如下。 # pd.read_csv is the function to save the csv format file from web url. pd.read_csv('https://github.com/datasets/covid-19/blob/master/data/countries-aggregated.csv ', parse_dates=['Date']) countries = ['Canada', 'Germany', 'United Kingdom', 'US', 'France', 'China'] 其中pd为提供的库，命令函数为read.csv(URL)，例如，直接进入URL抓取网络档案(逗号分隔的文本文件)，字段名为日期，分类国家为加拿大、德国、英国、美国、法国和中国。 图18.左边是原始数据，右边是读取后的格式化数据，按日期排序 # The definition of graphic colors and styles to present country data in different colors colors = {'Canada':'#045275', 'China':'#089099', 'France':'#7CCBA2', 'Germany':'#FCDE9C', 'US':'#DC3977', 'United Kingdom':'#7C1D6F'} plt.style.use('fivethirtyeight') # Create Visual Appearance, including graphic size, arrangement plot = covid.plot(figsize=(12,8), color=list(colors.values()), linewidth=5, legend=False) 根据网页上的描述，对方提供的Python库只需5分钟就可以完成程序训练，结果如图19所示。整个过程简单明了。代码行数不到20行，数据操作仅用了不到3行，其余均为对图片设计的处理。 图19.数据的可视化 测试 请在我们的jupyter服务器上测试代码并进行练习，默认账户名yuanzhuo，默认密码yuanzhuo. 请将kernel设置为conda-yuanzhuo. Yuanzhuo Online Code Platform 测验 推理的方法是( )\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"29115f872368f0c3eab6fdd4f63ded688d820a4e\"}\" data-id=\"29115f872368f0c3eab6fdd4f63ded688d820a4e\" class=\"mcqBox gitQuestion\">推理的方法是( ) A. B. C. D. SubmitHint COVID-19流行病期间，AI如何应用于医疗临床诊断？\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"d68072a99b123e09cee224b5824fc6812df720cf\"}\" data-id=\"d68072a99b123e09cee224b5824fc6812df720cf\" class=\"mcqBox gitQuestion\">COVID-19流行病期间，AI如何应用于医疗临床诊断？ A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/第四章计算机如何像人类一样学习.html":{"url":"content/第四章计算机如何像人类一样学习.html","title":"第四章 计算机如何像人类一样学习?","keywords":"","body":"第四章 计算机如何像人类一样学习? W人类从过去的经验中学习；相应的，计算机可以从数据中学习如何执行任务，而不是通过明确的编程方式，这就是所谓的机器学习。机器学习就是使用各种算法，从数据中反复学习，以改进、描述数据和预测结果。例如，如图20所示，在一个在线购物网站中，机器会通过记录某位顾客购买过的产品或浏览的产品来学习他/她的喜好或选择。然后，它将根据这些偏好开始向客户推荐客户可能喜欢的产品。 图 20. 计算机从购物数据中了解购物者 在机器学习中，可以归结为四种类型的学习: 1.**监督式学习**：在这种学习类型中，机器学习模型被提前教授一些知识，使得它可以预测未来的实例。举例说明，我们希望机器根据以下几点来知道学生X是勤奋、优秀还是懒惰的学生: **(1)** 他/她每天花多少时间学习; **(2)** 他/她看电视的时间。正如我们所提到的，我们需要先教机器；在这种情况下，我们必须给它提供以前关于其他学生的知识（也称为标签数据集），如表1所示。在表1给出的知识中可以看到，学生的类型是已知的（勤奋、优秀、懒惰）。机器将首先从这些知识中学习。然后，它将根据任何一个想要预测的新学生（例如，我们的学生X）花了多少小时学习和看电视来进行分类。 表 1. 对学生进行分类的知识信息（也称为标签数据集）实例 学生 学习时间 看电视时间 学生类型 张强 5 1 勤奋 李明 3 2 优秀 王正 2 3 懒惰 2.无监督学习：在这种学习类型中，我们不提前教授机器学习模型知识（如第一种情况）。因此，机器将在未标记的数据上工作，它将根据相似的模式或特征对这些数据进行分类或聚类。 3.强化学习：在这种学习类型中，机器将运行在一个交互环境中，并处于特定的状态。然后，它将利用环境的反馈，通过试错从自己的行动和经验中学习。我们以狗和主人之间的 \"捡球 \"游戏为例（见图21）。狗（机器）与主人（交互环境）在花园里，主人在花园里扔球（状态）。狗（机器）必须执行一个动作，可能是追球，也可能不是。如果狗捡到了球（动作），它的主人（互动环境）会通过给它食物来奖励它，通过这种方式，狗（机器）会知道它正在做正确的动作，它应该继续这样做。如果狗没有追球（动作），它的主人就不会给它食物。这样，狗（机器）就会知道自己做的动作是错误的，它应该去追球（正确的动作）。 图 21. 狗和主人之间的“捡球”游戏 4.深度学习：深度学习是一种特殊的机器学习方法，它在连续的层中加入了神经网络，以便以重复（迭代）的方式从数据中学习。当你试图从非结构化数据中学习到某种模式时，深度学习特别有用。 就像我们在上面看到的那样，机器学习可以根据给定的数据进行学习和预测。因此，给机器提供以下数据很重要: (1) 高质量的数据：准确和正确的数据可以帮助机器做出正确的决策; (2) 大量的数据：可以帮助机器学习到若干信息以执行动作和决策。举例来说，我们可以把机器看作是 \"汽车\"，而数据则是 \"燃料\"（见图22）。汽车没有燃料就不能工作，同样的，机器没有数据也不能工作。另外，如果我们给汽车提供大量优质的燃油，那么发动机就不会受到伤害，汽车就可以带我们远行。同样对于机器来说，高质量的数据不会对机器造成伤害，从而帮助它做出正确的决策，而大量的数据可以使它做出精确的决策或预测。 图 22. 数据对于机器学习的重要性 计算机数据 计算机数据是由计算机处理或存储的信息。这种信息可以是不同的形式，如文本、音频或图像。计算机数据由计算机的中央处理单元(CPU)处理，可以存储在计算机的硬盘或在线云端上。 各级医院和相关部门迫切需要建立互动的信息接口与连接，建立各方实时协作和信息共享的平台，使医疗机构之间、医疗机构与区域行政部门之间能够按照任务规定实现信息和数据共享，为管理和决策提供有效依据。在此背景下，最重要的是提供一个统一的、结构化的数据平台，使医生和科研人员可以方便地获取国际最新数据。例如，如图23所示，中国宁波市医疗卫生委员会在2020年初建立了新冠肺炎监测平台，可以对宁波市4000家医疗机构进行监测。所有的数据，如确诊病例、感染者年龄等都来自中国的医渡云。 图 23. 宁波市医疗卫生委员会建立的新冠肺炎监测平台，数据来自医渡云 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/4.1应用机器学习预测新冠疫情的传播情况.html":{"url":"content/4.1应用机器学习预测新冠疫情的传播情况.html","title":"4.1 应用机器学习预测新冠疫情的传播情况","keywords":"","body":"4.1 应用机器学习预测新冠疫情的传播情况 故事 10: 预测新冠肺炎病例的 AI工具 \"学校什么时候重新开学？新冠肺炎的演变过程是怎样的？疫情会持续多久？ 我们怎样才能知道这种流行病的趋势？\" 现在很多人都在问这些问题。为了回答所有这些问题，并预测病毒将如何传播，Tuli等人（2020）建立了一个机器学习模型，对新冠病例的数量和大流行可能结束的日期进行了很好的超前预测。例如，图24所示的模型显示了世界各地新增病例和死亡人数对应的曲线。 图 24. 关于新冠疫情期间全球新病例和死亡人数的预测模型 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/4.2应用机器学习制定疫情医疗解决方案.html":{"url":"content/4.2应用机器学习制定疫情医疗解决方案.html","title":"4.2 应用机器学习制定疫情医疗解决方案","keywords":"","body":"4.2 应用机器学习制定疫情医疗解决方案 在全球流行病疫情期间，AI可以成为医生最好的朋友，计算机可以用来加速寻找一些疾病的医疗解决方案或疫苗。例如，通过使用机器学习技术，可以快速对数十亿个化学化合物进行快速筛选，找到相关的候选药物。 故事 11: 应用机器学习帮助加速发现治疗新冠疫情的药物 科学家现在可以应用机器学习来加速新冠肺炎的药物寻找过程。例如，总部位于牛津的Exscientia公司现在正在使用机器学习技术来加速寻找有效药物的过程。具体来说，人工智能可以高效学习脱氧核糖酸（DNA）和病毒的结构并快速分析与药品信息相关的大数据，以确定那些有可能治疗新冠肺炎的药物。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/4.3实践学习体验：训练机器执行一个动作.html":{"url":"content/4.3实践学习体验：训练机器执行一个动作.html","title":"4.3 实践学习体验：训练机器执行一个动作","keywords":"","body":"4.3 实践学习体验：训练机器执行一个动作 卷积神经网络(CNN)主要应用于计算机视觉领域，并在各种测试案例上成功达到了最先进的性能。CNN中的隐藏层一般是卷积层和池化层（如果不懂的话，可以看做一层就是一个程序模块）。在每个卷积层中，我们取一个小尺寸的滤波器（也称为卷积核，是一个小尺寸的权重矩阵），并将该滤波器在图像上移动，进行卷积数学运算，来达到减少样本数的效果。卷积运算做法就是在过滤器中的数值和图像中的像素之间进行逐元素矩阵乘法，并将结果值相加。 CNN: 卷积神经网络 卷积神经网络（CNN）是一种前馈神经网络，一般通过处理网格状拓扑结构的数据来分析视觉图像。它也被称为ConvNet。卷积神经网络一般用于检测和分类图像中的物体。 CNN在计算上也很有效率。它使用特殊的卷积和池化操作，来实现参数共享。这使得CNN模型可以在任何设备上运行，从而得到普遍青睐。这一切听起来都像是纯粹的魔法：作为一个非常强大和高效的模型，它进行自动特征提取，以达到非一般的精度。所有的CNN模型都遵循类似的架构，如图25所示。 图 25. 卷积神经网络结构 现在，让我们继续学习池化层。池化层是用来缩小图像大小的。图像会包含大量的像素值，如果逐步缩小图像的大小，通常可以使网络很容易学习到特征。池化层有助于减少所需参数的数量，因此，这减少了所需的计算量。有两种类型的池化操作可以完成。 最大池化——选择最大值 平均池化——将所有数值相加，然后除以数值总数 在我们开始编码之前，你需要知道我们要使用的数据集是MNIST数字数据集（手写数字专用数据集），我们将使用Keras库和Tensorflow框架来建立模型。好了，准备充分之后，让我们来编写代码。 import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2Dimport numpy as np 首先，让我们做一些必要的导入。keras库帮助我们构建卷积神经网络。我们通过 keras 下载 mnist 数据集。然后，我们导入一个序列模型，这是一个预建的keras模型，你可以在其中添加层。接着，我们引入卷积层和池化层。我们还导入了全连接层，因为它们是用来预测标签的。dropout层可以减少过拟合，扁平化层可以将三维向量扩展为一维向量。最后，我们导入numpy进行矩阵操作。 batch_size = 128 num_classes = 10 epochs = 12 # input image dimensions img_rows, img_cols = 28, 28 # the data, split between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(60000,28,28,1) x_test = x_test.reshape(10000,28,28,1) print('x_train shape:', x_train.shape) print(x_train.shape[0], 'train samples') print(x_test.shape[0], 'test samples') # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) 上面代码中的大部分语句都会很琐碎，这里只对一些代码行进行解释。首先我们重构x_train和x_test，因为我们的CNN只接受一个四个维度向量。值60000代表训练数据中的图像数量，28代表图像大小（即长和宽都是28），1代表通道数。如果图像是灰度的，通道数设置为1，如果图像是RGB格式的，通道数设置为3。我们还将目标值转换为二进制类矩阵。要想知道二进制类矩阵是什么样的，请看下面的例子。 model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1))) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) 我们建立一个序列模型，并在其中添加卷积层和最大池化层。我们还在中间添加了dropout层，dropout会随机关闭网络中的一些传递数值，从而迫使数据兼顾新的神经传导路径。我们在最后添加了全连接层来整理数值，最终输出的结果是用来进行类别预测，也就是猜测手写的数值是否为0到9的数字。 model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test)) score = model.evaluate(x_test, y_test, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1]) 然后，我们将数据集拟合到模型上，即我们对模型进行12次迭代（回合）的训练。训练完模型后，我们评估模型在测试数据上的函数损失和准确性，并打印出来（见图26）.也就是判断每次输入的手写数字，最后猜测是否为正确分类结果。 图 26. 得到的输出结果 测试 请在我们的jupyter服务器上测试代码并进行练习，默认账户名yuanzhuo，默认密码yuanzhuo. 请将kernel设置为conda-yuanzhuo-tf-chapter4. (https://code.yuanzhuo.bnu.edu.cn/) 测验 深度学习是如何工作的?\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"cc7335b752902b283339add73fd00308feb0c1ad\"}\" data-id=\"cc7335b752902b283339add73fd00308feb0c1ad\" class=\"mcqBox gitQuestion\">深度学习是如何工作的? A. B. C. D. SubmitHint 关于卷积神经网络(CNN)，哪项说法不正确?\\n\",\"hint\":\"再次一次 ... -->\",\"count\":4,\"id\":\"a0e39fba34db19617cb268822cfee8c4508ab113\"}\" data-id=\"a0e39fba34db19617cb268822cfee8c4508ab113\" class=\"mcqBox gitQuestion\">关于卷积神经网络(CNN)，哪项说法不正确? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/第五章计算机能理解人类并与他们交谈吗.html":{"url":"content/第五章计算机能理解人类并与他们交谈吗.html","title":"第五章 计算机能理解人类并与他们交谈吗?","keywords":"","body":"第五章 计算机能理解人类并与他们交谈吗? 当前，人工智能技术应用于生活的方方面面，比如计算机已经能够与人类通过对话进行互动交流。很多公司也推出了他们的智能语音助手（如图27）。智能语音助手可以通过语音查询和自然语言来回答问题、提供建议，执行操作。 图 27. 可以与人类互动的智能虚拟助手的例子 为了实现自然语言交互并与人类交流，机器会执行下列步骤：(1)接受人类的输入，如语音；(2)分析输入(语音)，以确定语音内容；(3)进行推理，以得到准确的答案；(4)执行回应，回复用户或执行特定任务。为了提供更加智能的、仿佛是真的是在与人类交互的体验，机器使用到了自然语言处理（NLP）技术。图26所展示的是人类与智能语音助手之间的交流场景，人类通过语言交流让机器播放特定的音乐。 图 28. 人与智能语音助手之间的交流场景—小爱同学播放特定音乐 自然语言处理（NLP）的定义是：将计算技术应用于自然语言和语音的分析。也即利用计算机科学的不同技术（算法等）来理解和回应人类的语言及语音。自然语言处理主要包括以下两部分: 自然语言理解（NLU）。它主要围绕机器理解展开，这是一个对人工智能颇有挑战的问题。一个NLU系统需要以下组件 (1) 词典、解析器和语法规则 (2) 帮助理解的语义理论。 自然语言生成（NLG）的目标是生成自然语言。它使用到类似于知识库的机器表示系统来生成自然语言，它就像是数据和自然语言之间的翻译器。自然语言生成包括三个任务: (1) 文本规划—从知识库中提取相关内容; (2) 句子规划—选择合适的词，形成有意义的短语，与此同时还需要设定句子的语气 (3) 文本实现—将短语规划映射为句子结构. © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-09 "},"content/5.1智能聊天机器人回答用户对新冠肺炎疫情的咨询.html":{"url":"content/5.1智能聊天机器人回答用户对新冠肺炎疫情的咨询.html","title":"5.1 智能聊天机器人回答用户对新冠肺炎疫情的咨询","keywords":"","body":"5.1 智能聊天机器人回答用户对新冠肺炎的咨询 聊天机器人是一种计算机程序，人类可以使用多种输入方式与它进行交互，如语音、文字、手势和触摸等。在不同的场景中它有不同的名称，像是对话式人工智能机器人、人工智能聊天机器人、人工智能助理、智能虚拟助理、虚拟客户助理、数字助理、对话式代理、虚拟代理、对话式界面等等。 随着科技的发展与生活质量的提高，聊天机器人越来越受人们的欢迎。聊天机器人基于自然语言处理技术对输入的文字进行分析，得出一个最好的回答，并将其反馈给用户。了解一下智能聊天机器人都应该具备哪些能力: 智能理解 智能聊天机器人不仅需要正确理解用户的请求，并且还要能够考虑到其他的相关信息，如地理位置或者用户的对话偏好等，综合提供完整合理的回应。 记忆 在交互过程中允许聊天机器人记住交互相关的某些细节，隐性地了解用户情况，以便在之后对话中重用。例如，移动助理可能会通过之前的对话了解到用户更喜欢四川菜，因此在之后的交互过程中，用户如果要求推荐餐厅时将会使用到这一信息。 情感分析 聊天机器人应该具备辨识用户语气或情感的能力。对于面向商业客户服务的机器人，这种能力是尤为重要的。具备识别用户情感的能力，它就可以识别用户对提供的服务是否满意，从而更有效地进行应对。除此之外，情感分析能力也有其他的应用领域，如根据心情推荐特定类型的歌曲等。 个性 聊天机器人如果有其独有的个性，会加强用户在交流过程的参与感和对机器人助手的共情。有些公司会选择使用特定形象来强化机器人个性，在对话中的语气等也可以有效表达个性。 多终端同步 为了使用户有更加自然的交互体验，即使更换设备，聊天机器人也可以在上次用户离开的地方接上对话，实现无缝的人机交互。 话题切换 在交流过程中引导用户转向另一个话题，例如在用户询问产品是否有库存时询问支付方式等。此外，如果用户交互的主要目的没有达成，聊天机器人还应给予用户有效反馈。 故事 12: 类人型机器人对医院进行清洁 你能猜到机器人在做什么吗（见图29）？它正在新加坡亚历山德拉医院进行打扫卫生等工作。当有人靠近它时，机器人会自动停下来等待用户指令。它在医院可是很受欢迎的哦，有些病人还会向它招手。如果你有机会见到它，记得和它打招呼哦。 图 29. 医院的机器人清洁工 故事 13: 聊天机器人协助自我诊断新冠肺炎 你有没有想过可以通过与一个聊天机器人对话，解决你的健康问题以及相关急救问题？如图30所示，美国疾病控制和预防中心开发了一款名为“Clara”的聊天机器人，为人们提供疫情期间的医疗咨询。 图 30. 智能聊天机器人 “Clara” © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/5.2利用文本分析来了解分析网民对新冠疫情的关注.html":{"url":"content/5.2利用文本分析来了解分析网民对新冠疫情的关注.html","title":"5.2 利用文本分析来了解分析网民对新冠疫情的关注","keywords":"","body":"5.2 利用文本分析来了解分析网民对新冠疫情的关注 新冠疫情的爆发引发了人们的恐慌，信息的不完整和不准确也会加剧人们的不安。我们需要更好地理解和解决新冠疫情疫情期间的公众情绪，以实施适当的信息传递和政策决策。 自然语言处理可以帮助研究人员监测网络舆情，了解公众关注的热点问题。 公共卫生官员也可以使用相应技术手段追踪疫情相关话题。这可以帮助政府了解公共卫生领域的热点和优先事项，同时减少错误信息的传播，对个人和群体的健康起到积极作用。 故事 14:新冠疫情期间公众情绪洞察 疫情期间，人们的感受如何？这是一项非常复杂的任务。2020年6月11日，美国查尔斯顿大学的一项研究通过分析统计相关卫生组织的推特，得出了疫情特定期间的公众情绪情况。通过使用文本分析和数据可视化手段，他们证明随着时间的推移，随着美国疫情的加剧，人们对于病毒的恐惧也逐步攀升（见图31和32）。 图 31: 词云在twitter数据中的一个实例 图 32: 一些词云实例 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-15 "},"content/5.3实践学习体验句子切分.html":{"url":"content/5.3实践学习体验句子切分.html","title":"5.3 实践学习体验 句子切分","keywords":"","body":"5.3 实践学习体验: 句子切分 自然语言处理技术涉及如何处理句子标记和制定文档向量。句子切分（也叫句子划分）是将一段书面语言划分为句子。看起来似乎非常简单，例如在英语以及其他的一些语言中，只要看到了标点符号，就将句子分割开。但是也会存在一些问题，如英文中的缩略语可能会存在句号，在处理过程中这是需要考量的因素。在处理原始文本时，需要一个包含句号的缩写字典，它可以帮助我们在句子分割中避免句子边界的切割错误。在很多情况下，我们使用语料库来完成这项工作。 举个例子，我们来看一段关于著名的棋牌游戏西洋双陆棋的文字 “Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.” text = \"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\" sentences = nltk.sent_tokenize(text) for sentence in sentences: print(sentence) print() 作为输出，我们分别得到三个组成部分的句子 Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two-player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice. 基于此，我们可以学习如何处理词袋模型（bag-of-word）和统计文档向量。词袋模型（bag-of-word）是我们在处理文本时使用的一种流行而简单的特征提取技术。它描述了文档中每个词的出现情况。 要使用这个模型，我们需要： 设计一个已知词的词表（也叫标记） 选择已知词语存在的属性 在词袋模型中，任何关于词的顺序或结构的信息都会被抛弃，只考量词语在词表中的属性。这个模型可以了解一个已知的词是否出现在文档中，但不知道这个词在文档中的位置。一般来讲，相似的文档有相似的内容。同时，也可以通过内容了解到文档的含义，需要两个步骤 1. 加载数据 我们有一个review.txt文件，它是我们的数据，要把它作为一个数组来加载。文件内容是: I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it. 为了实现这一点，我们可以简单地读取文件，并按行分割 with open(\"simple movie reviews.txt\", \"r\") as file: documents = file.read().splitlines() print(documents) 输出是 'I like this movie, it's funny.', 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.' 2. 设计词表 让我们从四个句子中获取所有独特的单词，忽略大小写、标点符号和单字标记。这些词将成为我们的词表（已知词）。因此，我们需要对每个文档中的单词进行评分。这里的任务是将每个原始文本转换为数字的向量。最简单的打分方法是若该单词存在，则用1标记，若单词不存在，则用0标记。 现在，让我们看看如何使用上面提到的CountVectorizer类创建一个词袋模型。 # Import the libraries we need from sklearn.feature_extraction.text import CountVectorizerimport pandas as pd # Step 2. Design the Vocabulary # The default token pattern removes tokens of a single character. That's why we don't have the \"I\" and \"s\" tokens in the output count_vectorizer = CountVectorizer() # Step 3. Create the Bag-of-Words Model bag_of_words = count_vectorizer.fit_transform(documents) # Show the Bag-of-Words Model as a pandas DataFrame feature_names = count_vectorizer.get_feature_names() pd.DataFrame(bag_of_words.toarray(), columns = feature_names) 输出如下所示 对照一下我们的文本内容，这种学习方式就是NLP中自然语言的基本处理方式 I like this movie, it's funny.I hate this movie.This was awesome! I like it.Nice one. I love it. 测试 请在我们的jupyter服务器上测试代码并进行练习，默认账户名yuanzhuo，默认密码yuanzhuo. 请将kernel设置为conda-yuanzhuo. (https://code.yuanzhuo.bnu.edu.cn/) 小测 请选择适当的利用自然语言处理(NLP)对抗新冠肺炎的例子\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"20b11d40d155270ebc99c6e1bc0801ec1160f156\"}\" data-id=\"20b11d40d155270ebc99c6e1bc0801ec1160f156\" class=\"mcqBox gitQuestion\">请选择适当的利用自然语言处理(NLP)对抗新冠肺炎的例子 A. B. C. D. SubmitHint 自然语言过程（NLP）的主要内容是什么?\\n\",\"hint\":\"再试一次 ... -->\",\"count\":4,\"id\":\"48a240d74f5164150619dbc216fc4948f07fb489\"}\" data-id=\"48a240d74f5164150619dbc216fc4948f07fb489\" class=\"mcqBox gitQuestion\">自然语言过程（NLP）的主要内容是什么? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2022-07-08 "},"content/第六章人工智能将如何影响你的生活.html":{"url":"content/第六章人工智能将如何影响你的生活.html","title":"第六章 人工智能将如何影响你的生活?","keywords":"","body":"第六章 人工智能将如何影响你的生活? AI可能会对社会、生态和人类自身产生良好的影响，它影响着人类的思维和决策，影响着教育、科学、文化。人工智能可以为人类提供服务，但也引发了担忧。例如，种族主义问题、歧视、失业以及人工智能的不确定性带来的一系列问题等。以下的例子提醒人们在使用AI时应该注意的问题 在训练AI系统识别新冠肺炎的某些系统中，不准确的数据或特定的识别算法可能会导致决策失准。例如，当某人被感染时，系统可能会误判其未感染。这可能会带来严重的后果。 使用AI系统对人进行服务时，应充分考虑到隐私问题，加强监管，避免数据的滥用。 AI系统产生的数据可能存储在不同的服务器中（如医院服务器、机构服务器等），这些数据是属于个人的？——因为系统使用了他的数据），还是属于开发者/公司的？——因为它开发了系统，还是属于第三方（医院、机构等）的？——因为他们提供了数据收集和处理的服务器。数据所有权是人工智能领域应该考虑的一大问题 AI系统的工作方式，包括算法、数据收集和处理的透明度等也应引起重视 毫无疑问，AI和机器人技术等，将在未来接管更多工作。AI也将创造一大批全新的就业岗位。这些岗位需要诸多新的知识技能，比如计算机相关的网络、编程等。很多的学校正在更新他们的课程，以跟上AI技术的发展。为了更好地适应未来的就业需求，学习AI相关知识技能是非常重要的。 正如读本所述，AI在各个方面，尤其是医疗领域起了重要作用。但我们也不得不考虑上述一系列社会和伦理问题。人工智能的应用方式非常复杂，AI是好是坏，也必须从多个角度进行考虑。我们需要不断地学习和摸索，谨慎地为未来做出决定 小测 请选择正确的说法\\n\",\"hint\":\"Poor Pluto ... -->\",\"count\":4,\"id\":\"cf726f54db60afbc863f09d29c02c3e88fe0b9e5\"}\" data-id=\"cf726f54db60afbc863f09d29c02c3e88fe0b9e5\" class=\"mcqBox gitQuestion\">请选择正确的说法 A. B. C. D. SubmitHint AI不会带来哪些变化?\\n\",\"hint\":\"Poor Pluto ... -->\",\"count\":4,\"id\":\"ac4863d93dd45163cf4a31dc8f79ac7bdf5b2d15\"}\" data-id=\"ac4863d93dd45163cf4a31dc8f79ac7bdf5b2d15\" class=\"mcqBox gitQuestion\">AI不会带来哪些变化? A. B. C. D. SubmitHint © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/结束语.html":{"url":"content/结束语.html","title":"结束语","keywords":"","body":"结束语 在好莱坞电影中，AI通常被表现为末日场景中仇视人类的机器人。然而，在新冠肺炎疫情期间，AI却以超级英雄的姿态出现，它可以拯救人类于病毒之中，AI技术在医疗领域的一系列新的应用，正好适时地用于抗击新冠病毒的相关工作中，大大降低了全球疫情的传播。 读本名为《人工智能助力新冠肺炎疫情防控网络互动读本》，也是北京师范大学智慧学习研究院发布的第一本动书（ActionBook）。在AI时代，让年轻一代为充满挑战的未来做好准备至关重要，为了实现这一点，我们通过准备相关课程让他们熟悉AI的背景知识以及应用技能，这也是“青少年人工智能创新计划”（元卓计划）的目标。. 为了达到互动的目的，读本在AI与教育的领域中做了一次积极尝试，主要通过在线交互的形式，面向全球 9 到 15 岁青少年，以生动有趣的故事和实时交流互动，帮助他们在了解AI实际应用的同时，理解其中的基本原理，学习并尝试使用简单的AI代码，体验运用AI解决实际问题的乐趣，激发他们的兴趣以及进一步学习AI的意愿。也许未来新冠肺炎疫情还有死灰复燃的可能，但我们相信，在大人们积极备战、青少年们准备充分的情况下，任何的困难与挑战都将无法战胜我们。 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-16 "},"content/引用.html":{"url":"content/引用.html","title":"引用","keywords":"","body":"参考文献 AIMBOT, https://www.ubtrobot.com/cn/products/aimbot Artificial Solutions. (2020). Chatbots: The Definitive Guide. Build Your Own Convolution Neural Network in 5 mins, https://towardsdatascience.com/build-your-own-con-volution-neural-network-in-5-mins-4217c2cf964f Columbus, L. (2019) AI Skills Among The Most In-Demand For 2020. Accessed from: https://www.forbes.com/sites/louiscolumbus/2019/11/27/ai-skills-among-the-most-in-demand-for-2020/#77bbd7d86b44 Decision tree in Python, https://towardsdatascience.com/decision-tree-in-python-b433ae57fb93 Face Detection in just 5 lines of code, https://towardsdatascience.com/face-detection-in-just-5-lines-of-code-5cc6087cb1a9 Graesser, A. C., McNamara, D. S., Louwerse, M. M., & Cai, Z. (2004). Coh-metrix: analysis of text on cohesion and language. Behavior Research Methods, Instruments, & Computers: A Journal of the Psychonomic Society, Inc, 36(2), 193–202. Hygiene-obsessed Singapore deploys robots to keep coronavirus away in Asian Review, https://asia.nikkei.com/Business/Technology/Hygiene-obsessed-Singapore-deploys-robots-to-keep-coronavirus-away https://cvd.lti.cmu.edu, the demonstration of CDC in Carnegie Mellon University Internet of Business. (n.d.). Robotics, A.I will create 58 million jobs, decimate middle-class careers: World Economic Forum. Accessed from: https://internetofbusiness.com/robotics-a-i-will-create-jobs-but-decimate-middle-class-careers-wef/ McNamara, D. S., Graesser, A. C., McCarthy, P. M., & Cai, Z. (2014). Automated Evaluation of Text and Discourse with Coh-Metrix. Cambridge University Press. Tuli, Shreshth, et al. “Predicting the Growth and Trend of COVID-19 Pandemic using Machine Learning and Cloud Computing.” Internet of Things (2020): 100222. The CT evaluation of Carnegie Mellon University, https://www.yitutech.com/ The demonstration of AI-Based Triage and Monitoring System, http://www.diagnosticrobotics.com The AI perdition tool of the conversation, http://theconversation.com The demonstration of AI-Based Triage and Monitoring System, http://www.diagnosticrobotics.com Visualizing COVID-19 Data Beautifully in Python by Nik Piepenbreier, https://towardsdatascience.com/visual-izing-covid-19-data-beautifully-in-python-in-5-minutes-or-less-affc361b2c6a © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-14 "},"content/关于我们.html":{"url":"content/关于我们.html","title":"关于我们","keywords":"","body":"关于我们 © Smart Learning Institute of Beijing Normal University (SLIBNU), 2020 all right reserved，powered by GitbookRelease Date： 2020-09-11 "}}